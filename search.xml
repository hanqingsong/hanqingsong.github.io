<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java多线程编程核心技术-高洪岩-目录]]></title>
    <url>%2F2019%2F01%2F%E7%9B%AE%E5%BD%95%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF-%E9%AB%98%E6%B4%AA%E5%B2%A9-%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172前 言第1章 Java多线程技能， 1.1 进程和多线程的概念及线程的优点 1.2 使用多线程 1.2.1 继承Thread类 1.2.2 实现Runnable接口 1.2.3 实例变量与线程安全 1.2.4 留意i——与System.out.println（）的异常 1.3 currentThread（）方法 1.4 isAlive（）方法 1.5 sleep（）方法 1.6 getId（）方法 1.7 停止线程 1.7.1 停止不了的线程 1.7.2 判断线程是否是停止状态 1.7.3 能停止的线程——异常法 1.7.4 在沉睡中停止 1.7.5 能停止的线程——暴力停止 1.7.6 方法stop（）与java.lang.ThreadDeath异常 1.7.7 释放锁的不良后果 1.7.8 使用return停止线程 1.8 暂停线程 1.8.1 suspend与resume方法的使用 1.8.2 suspend与resume方法的缺点——独占 1.8.3 suspend与resume方法的缺点——不同步 1.9 yield方法 1.10 线程的优先级 1.10.1 线程优先级的继承特性 1.10.2 优先级具有规则性 1.10.3 优先级具有随机性 1.10.4 看谁运行得快 1.11 守护线程 1.12 本章小结第2章 对象及变量的并发访问 2.1 synchronized同步方法 2.1.1 方法内的变量为线程安全 2.1.2 实例变量非线程安全 2.1.3 多个对象多个锁 2.1.4 synchronized方法与锁对象 2.1.5 脏读 2.1.6 synchronized锁重入 2.1.7 出现异常，锁自动释放 2.1.8 同步不具有继承性 2.2 synchronized同步语句块 2.2.1 synchronized方法的弊端 2.2.2 synchronized同步代码块的使用 2.2.3 用同步代码块解决同步方法的弊端 2.2.4 一半异步，一半同步 2.2.5 synchronized代码块间的同步性 2.2.6 验证同步synchronized（this）代码块是锁定当前对象的 2.2.7 将任意对象作为对象监视器 2.2.8 细化验证3个结论 2.2.9 静态同步synchronized方法与synchronized（class）代码块 2.2.10 数据类型String的常量池特性 2.2.11 同步synchronized方法无限等待与解决 2.2.12 多线程的死锁 2.2.13 内置类与静态内置类 2.2.14 内置类与同步：实验1 2.2.15 内置类与同步：实验2 2.2.16 锁对象的改变 2.3 volatile关键字 2.3.1 关键字volatile与死循环 2.3.2 解决同步死循环 2.3.3 解决异步死循环 2.3.4 volatile非原子的特性 2.3.5 使用原子类进行i++操作 2.3.6 原子类也并不完全安全 2.3.7 synchronized代码块有volatile同步的功能 2.4 本章总结第3章 线程间通信 3.1 等待/通知机制 3.1.1 不使用等待/通知机制实现线程间通信 3.1.2 什么是等待/通知机制 3.1.3 等待/通知机制的实现 3.1.4 方法wait（）锁释放与notify（）锁不释放 3.1.5 当interrupt方法遇到wait方法 3.1.6 只通知一个线程 3.1.7 唤醒所有线程 3.1.8 方法wait（long）的使用 3.1.9 通知过早 3.1.10 等待wait的条件发生变化 3.1.11 生产者/消费者模式实现 3.1.12 通过管道进行线程间通信：字节流 3.1.13 通过管道进行线程间通信：字符流 3.1.14 实战：等待/通知之交叉备份 3.2 方法join的使用 3.2.1 学习方法join前的铺垫 3.2.2 用join（）方法来解决 3.2.3 方法join与异常 3.2.4 方法join（long）的使用 3.2.5 方法join（long）与sleep（long）的区别 3.2.6 方法join（）后面的代码提前运行：出现意外 3.2.7 方法join（）后面的代码提前运行：解释意外 3.3 类ThreadLocal的使用 3.3.1 方法get（）与null 3.3.2 验证线程变量的隔离性 3.3.3 解决get（）返回null问题 3.3.4 再次验证线程变量的隔离性 3.4 类InheritableThreadLocal的使用 3.4.1 值继承 3.4.2 值继承再修改 3.5 本章总结第4章 Lock的使用 4.1 使用ReentrantLock类 4.1.1 使用ReentrantLock实现同步：测试1 4.1.2 使用ReentrantLock实现同步：测试2 4.1.3 使用Condition实现等待/通知错误用法与解决 4.1.4 正确使用Condition实现等待/通知 4.1.5 使用多个Condition实现通知部分线程：错误用法 4.1.6 使用多个Condition实现通知部分线程：正确用法 4.1.7 实现生产者/消费者模式：一对一交替打印 4.1.8 实现生产者/消费者模式：多对多交替打印 4.1.9 公平锁与非公平锁 4.1.10 方法getHoldCount（）、getQueueLength（）和getWaitQueueLength（）的测试 4.1.11 方法hasQueuedThread（）、hasQueuedThreads（）和hasWaiters（）的测试 4.1.12 方法isFair（）、isHeldByCurrentThread（）和isLocked（）的测试 4.1.13 方法lockInterruptibly（）、tryLock（）和tryLock（long timeout，TimeUnit unit）的测试 4.1.14 方法awaitUninterruptibly（）的使用 4.1.15 方法awaitUntil（）的使用 4.1.16 使用Condition实现顺序执行 4.2 使用ReentrantReadWriteLock类 4.2.1 类ReentrantReadWriteLock的使用：读读共享 4.2.2 类ReentrantReadWriteLock的使用：写写互斥 4.2.3 类ReentrantReadWriteLock的使用：读写互斥 4.2.4 类ReentrantReadWriteLock的使用：写读互斥 4.3 本章总结第5章 定时器Timer 5.1 定时器Timer的使用 5.1.1 方法schedule（TimerTask task， Date time）的测试 5.1.2 方法schedule（TimerTask task， Date firstTime， long period）的测试 5.1.3 方法schedule（TimerTask task， long delay）的测试 5.1.4 方法schedule（TimerTask task， long delay， long period）的测试 5.1.5 方法scheduleAtFixedRate（TimerTask task， Date firstTime， long period）的测试 5.2 本章总结第6章 单例模式与多线程 6.1 立即加载/&quot;饿汉模式&quot; 6.2 延迟加载/&quot;懒汉模式&quot; 6.3 使用静态内置类实现单例模式 6.4 序列化与反序列化的单例模式实现 6.5 使用static代码块实现单例模式 6.6 使用enum枚举数据类型实现单例模式 6.7 完善使用enum枚举实现单例模式 6.8 本章总结第7章 拾遗增补 7.1 线程的状态 7.1.1 验证NEW、RUNNABLE和TERMINATED 7.1.2 验证TIMED_WAITING 7.1.3 验证BLOCKED 7.1.4 验证WAITING 7.2 线程组 7.2.1 线程对象关联线程组：1级关联 7.2.2 线程对象关联线程组：多级关联 7.2.3 线程组自动归属特性 7.2.4 获取根线程组 7.2.5 线程组里加线程组 7.2.6 组内的线程批量停止 7.2.7 递归与非递归取得组内对象 7.3 使线程具有有序性 7.4 SimpleDateFormat非线程安全 7.4.1 出现异常 7.4.2 解决异常方法1 7.4.3 解决异常方法2 7.5 线程中出现异常的处理 7.6 线程组内处理异常 7.7 线程异常处理的传递 7.8 本章总结]]></content>
      <categories>
        <category>目录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[实战Java高并发程序设计-葛一鸣-目录]]></title>
    <url>%2F2019%2F01%2F%E7%9B%AE%E5%BD%95%2F%E5%AE%9E%E6%88%98Java%E9%AB%98%E5%B9%B6%E5%8F%91%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1-%E8%91%9B%E4%B8%80%E9%B8%A3-%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187第1章走入并行世界 1.1何去何从的并行计算 1.1.1忘掉那该死的并行 1.1.2可怕的现实：摩尔定律的失效 1.1.3柳暗花明：不断地前进 1.1.4光明或是黑暗 1.2你必须知道的几个概念 1.2.1同步（Synchronous）和异步（Asynchronous） 1.2.2并发（Concurrency）和并行（Parallelism） 1.2.3临界区 1.2.4阻塞（Blocking）和非阻塞（Non—Blocking） 1.2.5死锁（Deadlock）、饥饿（Starvation）和活锁（Livelock） 1.3并发级别 1.3.1阻塞（Blocking） 1.3.2无饥饿（Starvation—Free） 1.3.3无障碍（Obstruction—Free） 1.3.4无锁（Lock—Free） 1.3.5无等待（Wait—Free） 1.4有关并行的两个重要定律 1.4.1Amdahl定律 1.4.2Gustafson定律 1.4.3Amdahl定律和Gustafson定律是否相互矛盾 1.5回到Java：JMM 1.5.1原子性（Atomicity） 1.5.2可见性（Visibility） 1.5.3有序性（Ordering） 1.5.4哪些指令不能重排：Happen—Before规则 1.6参考文献 第2章Java并行程序基础 2.1有关线程你必须知道的事 2.2初始线程：线程的基本操作 2.2.1新建线程 2.2.2终止线程 2.2.3线程中断 2.2.4等待（wait）和通知（notify） 2.2.5挂起（suspend）和继续执行（resume）线程 2.2.6等待线程结束（join）和谦让（yield） 2.3volatile与Java内存模型（JMM） 2.4分门别类的管理：线程组 2.5驻守后台：守护线程（Daemon） 2.6先干重要的事：线程优先级 2.7线程安全的概念与synchronized 2.8程序中的幽灵：隐蔽的错误 2.8.1无提示的错误案例 2.8.2并发下的ArrayList 2.8.3并发下诡异的HashMap 2.8.4初学者常见问题：错误的加锁 2.9参考文献 第3章JDK并发包 3.1多线程的团队协作：同步控制 3.1.1synchronized的功能扩展：重入锁 3.1.2重入锁的好搭档：Condition条件 3.1.3允许多个线程同时访问：信号量（Semaphore） 3.1.4ReadWriteLock读写锁 3.1.5倒计时器：CountDownLatch 3.1.6循环栅栏：CyclicBarrier 3.1.7线程阻塞工具类：LockSupport 3.2线程复用：线程池 3.2.1什么是线程池 3.2.2不要重复发明轮子：JDK对线程池的支持 3.2.3刨根究底：核心线程池的内部实现 3.2.4超负载了怎么办：拒绝策略 3.2.5自定义线程创建：ThreadFactory 3.2.6我的应用我做主：扩展线程池 3.2.7合理的选择：优化线程池线程数量 3.2.8堆栈去哪里了：在线程池中寻找堆栈 3.2.9分而治之：Fork／Join框架 3.3不要重复发明轮子：JDK的并发容器 3.3.1超好用的工具类：并发集合简介 3.3.2线程安全的HashMap 3.3.3有关List的线程安全 3.3.4高效读写的队列：深度剖析ConcurrentLinkedQueue 3.3.5高效读取：不变模式下的CopyOnWriteArrayList 3.3.6数据共享通道：BlockingQueue 3.3.7随机数据结构：跳表（SkipList） 3.4参考资料 第4章锁的优化及注意事项 4.1有助于提高“锁”性能的几点建议 4.1.1减小锁持有时间 4.1.2减小锁粒度 4.1.3读写分离锁来替换独占锁 4.1.4锁分离 4.1.5锁粗化 4.2Java虚拟机对锁优化所做的努力 4.2.1锁偏向 4.2.2轻量级锁 4.2.3自旋锁 4.2.4锁消除 4.3人手一支笔：ThreadLocal 4.3.1ThreadLocal的简单使用 4.3.2ThreadLocal的实现原理 4.3.3对性能有何帮助 4.4无锁 4.4.1与众不同的并发策略：比较交换（CAS） 4.4.2无锁的线程安全整数：AtomicInteger 4.4.3Java中的指针：Unsafe类 4.4.4无锁的对象引用：AtomicReference 4.4.5带有时间戳的对象引用：AtomicStampedReference 4.4.6数组也能无锁：AtomicIntegerArray 4.4.7让普通变量也享受原子操作：AtomicIntegerFieldUpdater 4.4.8挑战无锁算法：无锁的Vector实现 4.4.9让线程之间互相帮助：细看SynchronousQueue的实现 4.5有关死锁的问题 4.6参考文献 第5章并行模式与算法 5.1探讨单例模式 5.2不变模式 5.3生产者—消费者模式 5.4高性能的生产者—消费者：无锁的实现 5.4.1无锁的缓存框架：Disruptor 5.4.2用Disruptor实现生产者—消费者案例 5.4.3提高消费者的响应时间：选择合适的策略 5.4.4CPUCache的优化：解决伪共享问题 5.5Future模式 5.5.1Future模式的主要角色 5.5.2Future模式的简单实现 5.5.3JDK中的Future模式 5.6并行流水线 5.7并行搜索 5.8并行排序 5.8.1分离数据相关性：奇偶交换排序 5.8.2改进的插入排序：希尔排序 5.9并行算法：矩阵乘法 5.10准备好了再通知我：网络NIO 5.10.1基于Socket的服务端的多线程模式 5.10.2使用NIO进行网络编程 5.10.3使用NIO来实现客户端 5.11读完了再通知我：AIO 5.11.1AIOEchoServer的实现 5.11.2AIOEcho客户端实现 5.12参考文献 第6章Java8与并发 6.1Java8的函数式编程简介 6.1.1函数作为一等公民 6.1.2无副作用 6.1.3申明式的（Declarative） 6.1.4不变的对象 6.1.5易于并行 6.1.6更少的代码 6.2函数式编程基础 6.2.1FunctionalInterface注释 6.2.2接口默认方法 6.2.3lambda表达式 6.2.4方法引用 6.3一步一步走入函数式编程 6.4并行流与并行排序 6.4.1使用并行流过滤数据 6.4.2从集合得到并行流 6.4.3并行排序 6.5增强的Future：CompletableFuture 6.5.1完成了就通知我 6.5.2异步执行任务 6.5.3流式调用 6.5.4CompletableFuture中的异常处理 6.5.5组合多个CompletableFuture 6.6读写锁的改进：StampedLock 6.6.1StampedLock使用示例 6.6.2StampedLock的小陷阱 6.6.3有关StampedLock的实现思想 6.7原子类的增强 6.7.1更快的原子类：LongAdder 6.7.2LongAdder的功能增强版：LongAccumulator 6.8参考文献 第7章使用Akka构建高并发程序 7.1新并发模型：Actor 7.2Akka之HelloWorld 7.3有关消息投递的一些说明 7.4Actor的生命周期 7.5监督策略 7.6选择Actor 7.7消息收件箱（Inbox） 7.8消息路由 7.9Actor的内置状态转换 7.10询问模式：Actor中的Future 7.11多个Actor同时修改数据：Agent 7.12像数据库一样操作内存数据：软件事务内存 7.13一个有趣的例子：并发粒子群的实现 7.13.1什么是粒子群算法 7.13.2粒子群算法的计算过程 7.13.3粒子群算法能做什么 7.13.4使用Akka实现粒子群 7.14参考文献 第8章并行程序调试 8.1准备实验样本 8.2正式起航 8.3挂起整个虚拟机 8.4调试进入ArrayList内部]]></content>
      <categories>
        <category>目录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java中HashMap源码笔记]]></title>
    <url>%2F2019%2F01%2FJava%2Fjava%E4%B8%ADHashMap%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[HashMap概述HashMap基于哈希表的 Map 接口的实现。并允许使用 null 值和 null 键。（除了不同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）HashMap的数据结构使用数组和链表来实现对数据的存储，jdk1.8之后链表节点达到8之后转为红黑树。默认初始化容量为16（DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16），扩容因子0.75（DEFAULT_LOAD_FACTOR = 0.75f），树化链表值是8（TREEIFY_THRESHOLD = 8）。HashMap为线程不安全，多线程操作会导致其死循环。 数组+链表数据结构HashMap的底层主要是基于数组和链表来实现的，它之所以有相当快的查询速度主要是因为它是通过计算散列码来决定存储的位置。如果存储的对象对多了，就有可能不同的对象所算出来的hash值是相同的，这就出现了所谓的hash冲突。解决hash冲突的方法有很多，HashMap底层是通过链表来解决hash冲突的。数组的特点是：寻址容易，插入和删除困难。链表的特点是：寻址困难，插入和删除容易。 put插入方法put数据过程 key计算hash值 找位置，根据hash值取模找对应的数组中位置，（取模操作(n - 1) &amp; hash，n为数组的长度，相当于hash%n，位运算效率更高 ） 放入数据，如果为空放入数组，如果有hash碰撞，放入链表中，如果链表长度超过8，转化为红黑树 判断大小是否需要扩容 先把key做下hash值计算：hash(key)123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 根据hash值判断放入数组链表相应位置中，12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don&apos;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // tab 数组，p指向节点， n数组长度，i取模索引位置 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 数组没有创建初始化数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 找放入的位置 // 1. 如果数组hash对应索引元素为空，创建数据赋值 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 2. 如果和第一个节点hash值相同，key值相同，已存在 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 3. 如果是红黑树节点，放入树节点 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 4. hash冲突，放到链表最后一个节点，或者转换为树 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果已经存在，则替换为新value if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 判断大小是否超过阀值 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; get查询方法get数据过程 key计算hash值 找位置，如果第一key值相同，直接返回，不相同遍历链表中数据 1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 12345678910111213141516171819202122232425262728293031/** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // (n - 1) &amp; hash 就是取模定位数组的索引 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 数组中找到，返回 return first; // 找链表中数据 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) // 递归树查找 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; // 遍历链表 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 数组长度为什么总是设定为 2 的 N 次方？ 取模快。其实就是上面为什么快的原因：位与取模比 % 取模要快的多。 分散平均，减少碰撞。这个是主要原因。如果二进制某位包含 0，则此位置上的数据不同对应的 hash 却是相同，碰撞发生，而 (2^x - 1) 的二进制是 0111111…，分散非常平均，碰撞也是最少的。 解决hash冲突的办法 开放定址法（线性探测再散列，二次探测再散列，伪随机探测再散列） 再哈希法 链地址法 建立一个公共溢出区 hashmap的解决办法就是采用的链地址法 参考资料https://blog.csdn.net/fighterandknight/article/details/61624150http://jayfeng.com/2016/12/28/%E7%90%86%E8%A7%A3HashMap/]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm方法区内存溢出]]></title>
    <url>%2F2018%2F07%2FJVM%2Fjvm%E6%96%B9%E6%B3%95%E5%8C%BA%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[java.lang.OutOfMemoryError: PermGen space jps查看java程序pid 保存heap：jmap -dump:format=b,file=heap.hprof pid，之后使用java自带工具jvisualvm分析数据 top查看cpu占用情况 top -H -p pid查看该进程具体线程情况 或者ps -mp pid -o THREAD,did,time 查看问题线程堆栈 ，查看该线程的堆栈情况，先将线程id转为16进制，使用printf “%x\n” tid命令进行转换，再使用jstack命令打印线程堆栈信息，命令格式：jstack pid |grep tid -A 30 jstat -gcutil pid 2000 10 命令查看进程的内存情况 jstack命令查看进程的堆栈情况]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot和redis实现session共享]]></title>
    <url>%2F2018%2F07%2Fspring%E5%AE%B6%E6%97%8F%2FSpringBoot%E5%92%8Credis%E5%AE%9E%E7%8E%B0session%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[添加@EnableRedisHttpSession来开启spring session支持 1234@Configuration @EnableRedisHttpSession public class RedisSessionConfig &#123; &#125; @EnableRedisHttpSession这个注解是由spring-session-data-redis提供的，所以在pom.xml文件中添加 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; application.yml 添加redis配置 1234spring: redis.host: xxxxxx redis.port: xxxx redis.password: xxxx idea启动项目两个实例4.1 选择“Edit Configurations”，取消“Single instance only”选项4.2 复制springboot 运行配置4.3 在VM options项中填写-Dserver.port=8082，设置这个实例的运行端口为8082]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>后端</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中对象克隆]]></title>
    <url>%2F2018%2F06%2FJava%2Fjava%E4%B8%AD%E5%AF%B9%E8%B1%A1%E5%85%8B%E9%9A%86%2F</url>
    <content type="text"><![CDATA[浅克隆在Java语言中，所有的Java类都继承自java.lang.Object。事实上，Object类提供一个clone()方法，可以将一个Java对象复制一份。因此在Java中可以直接使用Object提供的clone()方法来实现对象的克隆。需要注意的是能够实现克隆的类必须实现接口Cloneable。1234567Object object = null;try &#123; object = super.clone();&#125; catch (CloneNotSupportedException exception) &#123; System.err.println(&quot;Not support cloneable&quot;);&#125;return (Prototype )object; 深克隆在Java语言中，如果需要实现深克隆，可以通过序列化(Serialization)等方式来实现。序列化就是将对象写到流的过程，写到流中的对象是原有对象的一个拷贝，而原对象仍然存在于内存中。通过序列化实现的拷贝不仅可以复制对象本身，而且可以复制其引用的成员对象，因此通过序列化将对象写到一个流中，再从流里将其读出来，可以实现深克隆。需要注意的是能够实现序列化的对象其类必须实现Serializable接口，否则无法实现序列化操作。123456789//将对象写入流中ByteArrayOutputStream bao=new ByteArrayOutputStream();ObjectOutputStream oos=new ObjectOutputStream(bao);oos.writeObject(this);//将对象从流中取出ByteArrayInputStream bis=new ByteArrayInputStream(bao.toByteArray());ObjectInputStream ois=new ObjectInputStream(bis);return (WeeklyLog)ois.readObject(); 资料原型模式 https://blog.csdn.net/lovelion/article/details/7424623]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git升级版本]]></title>
    <url>%2F2018%2F06%2F%E5%B7%A5%E5%85%B7%2Fgit%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[在使用git pull、git push、git clone的时候，会报如下的错误：error: while accessing https://github.com/Yelp/elastalert.git/info/refs fatal: HTTP request failed这个一般是由于服务器本身自带的git版本过低造成的：12git --versiongit version 1.7.1 git版本升级123456789101112131415161718192021222324252627280）安装依赖软件[root@uatjenkins01 ~]# yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc[root@uatjenkins01 ~]# yum install gcc perl-ExtUtils-MakeMaker 1）卸载系统自带的底版本git（1.7.1）[root@uatjenkins01 ~]# git --versiongit version 1.7.1[root@uatjenkins01 ~]# yum remove git 2）编译安装最新的git版本[root@uatjenkins01 ~]# cd /usr/local/src/[root@uatjenkins01 src]# wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.17.1.tar.gz[root@uatjenkins01 src]# tar -vxf git-2.17.1.tar.xz[root@uatjenkins01 src]# cd git-2.17.1[root@uatjenkins01 git-2.17.1]# make prefix=/usr/local/git all[root@uatjenkins01 git-2.17.1]# make prefix=/usr/local/git install[root@uatjenkins01 git-2.17.1]# echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/profile[root@uatjenkins01 git-2.17.1]# source /etc/profile [root@uatjenkins01 ~]# git --versiongit version 2.17.1 ======================================================================如果是非root用户使用git，则需要配置下该用户下的环境变量[app@uatjenkins01 ~]$ echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; ~/.bashrc[app@uatjenkins01 ~]$ source ~/.bashrc[app@uatjenkins01 ~]$ git --versiongit version 2.17.1]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EFK-日志报警]]></title>
    <url>%2F2018%2F06%2FELK%2FEFK-%E6%97%A5%E5%BF%97%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[Elastalert 安装下载 elastalert 源码1234git clone https://github.com/Yelp/elastalert.gitcd elastalertpython setup.py installpip install -r requirements.txt 安装完后，会在 /usr/local/bin/ 下生成4个elastalert命令1234/usr/local/bin/elastalert /usr/local/bin/elastalert-create-index /usr/local/bin/elastalert-rule-from-kibana /usr/local/bin/elastalert-test-rule elastalert-create-index 这个命令会在elasticsearch创建索引，这不是必须的步骤，但是强烈建议创建。因为对于，审计，测试很有用，并且重启elastalert不影响计数和发送alert,默认情况下，创建的索引叫 elastalert_status Elastalert 配置配置文件config.yaml/mydata/elk/elastalert/config.yaml 12345678910111213141516171819202122232425262728# 规则文件夹rules_folder: my_rules# 查询Elasticsearch时间间隔run_every: minutes: 1# ElastAlert缓存结果时间buffer_time: minutes: 15# Elasticsearch hostnamees_host: 127.0.0.1es_port: 9200# elasticsearch中的索引名writeback_index: elastalert_status# 发送失败重试时间间隔alert_time_limit: days: 2# 邮箱发送配置smtp_host: smtp.exmail.qq.comsmtp_port: 465smtp_ssl: truesmtp_auth_file: /mydata/elk/elastalert/email_auth.yamlfrom_addr: xxx@xxx.cn 规则 example_rules12345678910111213141516171819202122232425# 规则名，需要唯一name: pay error frequency rule# 数据验证方式type: frequency# 从某类索引里读取数据index: filebeat-*# 在时间间隔内匹配多少次触发报警num_events: 1# 时间间隔timeframe: minutes: 1# ES请求的过滤条件filter:- query: query_string: query: &apos;source:&quot;/mydata/release/fs-pay/logs/error.log&quot; AND message:ERROR&apos;# 报警渠道alert:- &quot;email&quot;email:- &quot;xxxx@xxx.cn&quot; 自定义邮件内容可以配置 alert_text和alert_text_args 控制报警风暴，减少重复告警的频率1234567891011121314# 用来区分报警，跟 realert 配合使用，在这里意味着，# 5 分钟内如果有重复报警，那么当 name 不同时，会当做不同的报警处理，可以是数组query_key: - name# 5 分钟内相同的报警不会重复发送realert: minutes: 5# 指数级扩大 realert 时间，中间如果有报警，# 则按照 5 -&gt; 10 -&gt; 20 -&gt; 40 -&gt; 60 不断增大报警时间到制定的最大时间，# 如果之后报警减少，则会慢慢恢复原始 realert 时间exponential_realert: hours: 1 ruletype1234567891011121314151617any：只要有匹配就报警；blacklist：compare_key字段的内容匹配上 blacklist数组里任意内容；whitelist：compare_key字段的内容一个都没能匹配上whitelist数组里内容；change：在相同query_key条件下，compare_key字段的内容，在 timeframe范围内 发送变化；frequency：在相同 query_key条件下，timeframe 范围内有num_events个被过滤出 来的异常；spike：在相同query_key条件下，前后两个timeframe范围内数据量相差比例超过spike_height。其中可以通过spike_type设置具体涨跌方向是- up,down,both 。还可以通过threshold_ref设置要求上一个周期数据量的下限，threshold_cur设置要求当前周期数据量的下限，如果数据量不到下限，也不触发；flatline：timeframe 范围内，数据量小于threshold 阈值；new_term：fields字段新出现之前terms_window_size(默认30天)范围内最多的terms_size (默认50)个结果以外的数据；cardinality：在相同 query_key条件下，timeframe范围内cardinality_field的值超过 max_cardinality 或者低于min_cardinality 启动启动elastalert服务，监听elasticsearch1234567python -m elastalert.elastalert --verbosepython -m elastalert.elastalert --verbose --rule example_rules/example_test.yaml后台运行nohup python -m elastalert.elastalert --verbose &gt;/dev/null 2&gt;&amp;1 &amp;指定配置文件nohup python -m elastalert.elastalert --verbose --rule example_rules/example_test.yaml &gt;/dev/null 2&gt;&amp;1 &amp; 资料https://elastalert.readthedocs.io/en/latest/https://www.ctolib.com/docs/sfile/ELKstack-guide-cn/elasticsearch/other/elastalert.htmlhttps://blog.xizhibei.me/2017/11/19/alerting-with-elastalert/http://www.freebuf.com/articles/web/160254.htmlhttp://www.xiaot123.com/post/elk_filebeat1]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志系统</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot接收时间参数]]></title>
    <url>%2F2018%2F06%2Fspring%E5%AE%B6%E6%97%8F%2FSpringBoot%E6%8E%A5%E6%94%B6%E6%97%B6%E9%97%B4%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[需求服务端需要使用实体类属性字段接收时间，java.util.Date类型的属性字段。 问题请求数据时间格式为：”yyyy-MM-dd HH:mm:ss” 字符串报错12345678&#123; &quot;timestamp&quot;: 1527824946500, &quot;status&quot;: 400, &quot;error&quot;: &quot;Bad Request&quot;, &quot;exception&quot;: &quot;org.springframework.http.converter.HttpMessageNotReadableException&quot;, &quot;message&quot;: &quot;JSON parse error: Can not deserialize value of type java.util.Date from String \&quot;2018-06-01 11:33:55\&quot;: not a valid representation (error: Failed to parse Date value &apos;2018-06-01 11:33:55&apos;: Can not parse date \&quot;2018-06-01 11:33:55\&quot;: while it seems to fit format &apos;yyyy-MM-dd&apos;T&apos;HH:mm:ss.SSS&apos;, parsing fails (leniency? null)); nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Can not deserialize value of type java.util.Date from String \&quot;2018-06-01 11:33:55\&quot;: not a valid representation (error: Failed to parse Date value &apos;2018-06-01 11:33:55&apos;: Can not parse date \&quot;2018-06-01 11:33:55\&quot;: while it seems to fit format &apos;yyyy-MM-dd&apos;T&apos;HH:mm:ss.SSS&apos;, parsing fails (leniency? null))\n at [Source: java.io.PushbackInputStream@73f25959; line: 1, column: 228] (through reference chain: cn.xxx[\&quot;rightsEndTime\&quot;])&quot;, &quot;path&quot;: &quot;/grouppurchase/commodity/add&quot;&#125; Springboot使用的默认json解析框架是jackjson框架 jackjson解析框架在解析实体类里面是date数据类型的数据时的默认格式是：UTC类型，即yyyy-MM-dd’T’HH:mm:ss.SSS 并且默认为+8时区，即时间基础上加8小时 解决方案实体Date类型的字段上使用@JsonFormat注解格式化日期1@JsonFormat(locale=&quot;zh&quot;, timezone=&quot;GMT+8&quot;, pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;) 取消timestamps形式1objectMapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false); fastjson解法方法1@JsonFormat(shape=JsonFormat.Shape.STRING, pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;)]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>后端</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java版本升级特性]]></title>
    <url>%2F2018%2F05%2FJava%2Fjava%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[相关名词JUG：Java User Groups（Java用户群）JCP：Java Community Process，一个促进Java发展的国际组织，主要负责JSR的制定，OpenJDK的开发。其中JUG属于JCP。EC：Executive Committee，是JCP中的执行委员会，是选举产生的。JEP（JDK Enhancement Proposal，JDK改进提案，JDK增强建议），来源于JCP社区，但不一定被采纳。JSR：Java Specification Requests（Java规范请求），JSR是有状态的，并不是所有的JSR都有效，所以在看JSR时需要先看下状态是否有效。Java的各个版本的语言规范和虚拟机规范都是JSR范畴里的，JSR的生效由Expert Group（专家组）商讨制定并由EC投票确立。JSR的确立是有一个具体流程规范的，不过并不是所有的JSR都会在JDK里实现的。JSR专家组（Expert Group）：从JCP里选出的对应领域有威望的个人（其实背后代表的是所属公司），负责制定和修改JSR。Java语言规范：其实已经包括在JSR里，细分开是因为只是语言层面的，不涉及跨平台的JVM的细节，所以想要详细了解Java语法的可以仔细研读下。JVM规范：这里主要描述虚拟机的实现规范，包括指令集及其作用、虚拟机内存模型、类文件描述、编译、链接、加载、初始化等步聚描述，想要了解虚拟机具体是怎么工作的可以仔细研读下，不过规范不涉及实现，目前虚拟机的实现也有很多种，HotSpot是OpenJDK里的，想要了解实现细节的可以下载HotSpot源码看下。 Java 11 新特性123456789101112131415161718官网公开的 17 个 JEP（JDK Enhancement Proposal 特性增强提议）：181: Nest-Based Access Control（基于嵌套的访问控制）309: Dynamic Class-File Constants（动态的类文件常量）315: Improve Aarch64 Intrinsics（改进 Aarch64 Intrinsics）318: Epsilon: A No-Op Garbage Collector（Epsilon 垃圾回收器，又被称为&quot;No-Op（无操作）&quot;回收器）320: Remove the Java EE and CORBA Modules（移除 Java EE 和 CORBA 模块，JavaFX 也已被移除）321: HTTP Client (Standard)323: Local-Variable Syntax for Lambda Parameters（用于 Lambda 参数的局部变量语法）324: Key Agreement with Curve25519 and Curve448（采用 Curve25519 和 Curve448 算法实现的密钥协议）327: Unicode 10328: Flight Recorder（飞行记录仪）329: ChaCha20 and Poly1305 Cryptographic Algorithms（实现 ChaCha20 和 Poly1305 加密算法）330: Launch Single-File Source-Code Programs（启动单个 Java 源代码文件的程序）331: Low-Overhead Heap Profiling（低开销的堆分配采样方法）332: Transport Layer Security (TLS) 1.3（对 TLS 1.3 的支持）333: ZGC: A Scalable Low-Latency Garbage Collector (Experimental)（ZGC：可伸缩的低延迟垃圾回收器，处于实验性阶段）335: Deprecate the Nashorn JavaScript Engine（弃用 Nashorn JavaScript 引擎）336: Deprecate the Pack200 Tools and API（弃用 Pack200 工具及其 API） java 10123456286：本地变量类型推断296：统一JDK仓库304：垃圾回收器接口307：G1的并行Full GC310：应用程序类数据共享312：ThreadLocal握手机制 java 9123456789Java 平台级模块系统LinkingJShell : 交互式 Java REPL改进的 Javadoc集合工厂方法改进的 Stream API私有接口方法HTTP/2多版本兼容 JAR 前辍说明：U:修改，A:新增，D:废弃，M:模块化，S:安全12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091U 102: Process API UpdatesA 110: HTTP 2 ClientU 143: Improve Contended LockingU 158: Unified JVM LoggingU 165: Compiler ControlU 193: Variable HandlesU 197: Segmented Code CacheU 199: Smart Java Compilation, Phase TwoAM 200: The Modular JDKAM 201: Modular Source CodeA 211: Elide Deprecation Warnings on Import StatementsA 212: Resolve Lint and Doclint WarningsU 213: Milling Project CoinD 214: Remove GC Combinations Deprecated in JDK 8A 215: Tiered Attribution for javacU 216: Process Import Statements CorrectlyU 217: Annotations Pipeline 2.0A 219: Datagram Transport Layer Security (DTLS)AM 220: Modular Run-Time ImagesA 221: Simplified Doclet APIA 222: jshell: The Java Shell (Read-Eval-Print Loop)A 223: New Version-String SchemeU 224: HTML5 JavadocA 225: Javadoc SearchA 226: UTF-8 Property FilesA 227: Unicode 7.0A 228: Add More Diagnostic CommandsUS 229: Create PKCS12 Keystores by DefaultD 231: Remove Launch-Time JRE Version SelectionU 232: Improve Secure Application PerformanceA 233: Generate Run-Time Compiler Tests AutomaticallyA 235: Test Class-File Attributes Generated by javacA 236: Parser API for NashornA 237: Linux/AArch64 PortU 238: Multi-Release JAR FilesD 240: Remove the JVM TI hprof AgentD 241: Remove the jhat ToolA 243: Java-Level JVM Compiler InterfaceUS 244: TLS Application-Layer Protocol Negotiation ExtensionU 245: Validate JVM Command-Line Flag ArgumentsUS 246: Leverage CPU Instructions for GHASH and RSAU 247: Compile for Older Platform VersionsU 248: Make G1 the Default Garbage CollectorAS 249: OCSP Stapling for TLSU 250: Store Interned Strings in CDS ArchivesA 251: Multi-Resolution ImagesU 252: Use CLDR Locale Data by DefaultA 253: Prepare JavaFX UI Controls &amp; CSS APIs for ModularizationU 254: Compact StringsU 255: Merge Selected Xerces 2.11.0 Updates into JAXPU 256: BeanInfo AnnotationsU 257: Update JavaFX/Media to Newer Version of GStreamerU 258: HarfBuzz Font-Layout EngineA 259: Stack-Walking APIUM 260: Encapsulate Most Internal APIsAM 261: Module SystemU 262: TIFF Image I/OA 263: HiDPI Graphics on Windows and LinuxA 264: Platform Logging API and ServiceU 265: Marlin Graphics RendererU 266: More Concurrency UpdatesA 267: Unicode 8.0A 268: XML CatalogsA 269: Convenience Factory Methods for CollectionsU 270: Reserved Stack Areas for Critical SectionsU 271: Unified GC LoggingA 272: Platform-Specific Desktop FeaturesA 273: DRBG-Based SecureRandom ImplementationsU 274: Enhanced Method HandlesAM 275: Modular Java Application PackagingAM 276: Dynamic Linking of Language-Defined Object ModelsU 277: Enhanced DeprecationA 278: Additional Tests for Humongous Objects in G1U 279: Improve Test-Failure TroubleshootingU 280: Indify String ConcatenationA 281: HotSpot C++ Unit-Test FrameworkAM 282: jlink: The Java LinkerA 283: Enable GTK 3 on LinuxU 284: New HotSpot Build SystemA 285: Spin-Wait HintsAS 287: SHA-3 Hash AlgorithmsDS 288: Disable SHA-1 CertificatesD 289: Deprecate the Applet APIAS 290: Filter Incoming Serialization DataD 291: Deprecate the Concurrent Mark Sweep (CMS) Garbage CollectorA 292: Implement Selected ECMAScript 6 Features in NashornA 294: Linux/s390x PortA 295: Ahead-of-Time CompilationU 297: Unified arm32/arm64 PortD 298: Remove Demos and SamplesU 299: Reorganize Documentation java81234567891011允许在接口中有默认方法实现Lambda表达式函数式接口方法和构造函数引用Lambda的范围内置函数式接口StreamsParallel StreamsMap时间日期APIAnnotations java7123456789switch语句块中允许以字符串作为分支条件；在创建泛型对象时应用类型推断；在一个语句块中捕获多种异常；支持动态语言；支持try-with-resources；引入Java NIO.2开发包；数值类型可以用2进制字符串表示，并且可以在字符串表示中添加下划线；try-with-resources(新语法)。定义在try-with-resources 声明里，无论try语句正常还是异常的结束， 它都会自动的关掉 java61234567支持脚本语言；引入JDBC 4.0 API；引入Java Compiler API；可插拔注解；增加对Native PKI(Public Key Infrastructure)、Java GSS(Generic Security Service)、Kerberos和LDAP(Lightweight Directory Access Protocol)的支持；继承Web Services；做了很多优化。 java512345678引入泛型；增强循环，可以使用迭代方式；自动装箱与自动拆箱；类型安全的枚举；可变参数；静态引入；元数据（注解）；引入Instrumentation。 资料https://juejin.im/entry/5aa234b35188255570059b78https://segmentfault.com/a/1190000004417830]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[quartz和数据库断连接的解决办法]]></title>
    <url>%2F2018%2F05%2Fquartz%2Fquartz%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%AD%E8%BF%9E%E6%8E%A5%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[quartz连接数据库超时会出现以下异常1234567891011121314151617181920212223242526272829303132333435363738394041com.mysql.jdbc.exceptions.jdbc4.MySQLNonTransientConnectionException: No operations allowed after connection closed. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:404) at com.mysql.jdbc.Util.getInstance(Util.java:387) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:917) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:896) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:885) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:860) at com.mysql.jdbc.ConnectionImpl.throwConnectionClosedException(ConnectionImpl.java:1246) at com.mysql.jdbc.ConnectionImpl.checkClosed(ConnectionImpl.java:1241) at com.mysql.jdbc.ConnectionImpl.rollback(ConnectionImpl.java:4564) at com.mchange.v2.c3p0.impl.NewProxyConnection.rollback(NewProxyConnection.java:855) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.quartz.impl.jdbcjobstore.AttributeRestoringConnectionInvocationHandler.invoke(AttributeRestoringConnectionInvocationHandler.java:73) at com.sun.proxy.$Proxy120.rollback(Unknown Source) at org.quartz.impl.jdbcjobstore.JobStoreSupport.rollbackConnection(JobStoreSupport.java:3666) at org.quartz.impl.jdbcjobstore.JobStoreSupport.executeInNonManagedTXLock(JobStoreSupport.java:3825) at org.quartz.impl.jdbcjobstore.JobStoreSupport.acquireNextTriggers(JobStoreSupport.java:2756) at org.quartz.core.QuartzSchedulerThread.run(QuartzSchedulerThread.java:272)Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: The last packet successfully received from the server was 50,340,121 milliseconds ago. The last packet sent successfully to the server was 50,340,121 milliseconds ago. is longer than the server configured value of &apos;wait_timeout&apos;. You should consider either expiring and/or testing connection validity before use in your application, increasing the server configured values for client timeouts, or using the Connector/J connection property &apos;autoReconnect=true&apos; to avoid this problem. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.mysql.jdbc.Util.handleNewInstance(Util.java:404) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:988) at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3739) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2508) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2673) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2545) at com.mysql.jdbc.ConnectionImpl.setAutoCommit(ConnectionImpl.java:4842) at com.mchange.v2.c3p0.impl.NewProxyConnection.setAutoCommit(NewProxyConnection.java:881) at org.quartz.impl.jdbcjobstore.AttributeRestoringConnectionInvocationHandler.setAutoCommit(AttributeRestoringConnectionInvocationHandler.java:98) at org.quartz.impl.jdbcjobstore.AttributeRestoringConnectionInvocationHandler.invoke(AttributeRestoringConnectionInvocationHandler.java:66) 解法方法：在使用链接时先检查是否有效123prop.put(&quot;org.quartz.dataSource.quartz.idleConnectionValidationSeconds&quot;, 60);prop.put(&quot;org.quartz.dataSource.quartz.validateOnCheckout&quot;, true);prop.put(&quot;org.quartz.dataSource.quartz.validationQuery&quot;, &quot;select 1&quot;); 配置说明1234567891011121314151617181920212223242526org.quartz.dataSource.NAME.driver必须是数据库的JDBC驱动程序的java类名称。org.quartz.dataSource.NAME.URL连接到数据库的连接URL（主机，端口等）。org.quartz.dataSource.NAME.user连接到数据库时要使用的用户名。org.quartz.dataSource.NAME.password连接到数据库时使用的密码。org.quartz.dataSource.NAME.maxConnectionsDataSource可以在其连接池中创建的最大连接数。org.quartz.dataSource.NAME.validationQuery是可选的SQL查询字符串，DataSource可用于检测和替换失败/损坏的连接。例如，oracle用户可能会选择“从user_tables中选择table_name” - 这是一个不应该失败的查询 - 除非连接实际上是坏的。org.quartz.dataSource.NAME.idleConnectionValidationSeconds空闲连接测试之间的秒数 - 仅在设置验证查询属性时启用。默认值为50秒。org.quartz.dataSource.NAME.validateOnCheckout每次从池中检索连接时，是否应该执行数据库sql查询来验证连接，以确保它仍然有效。如果为假，则在办理登机手续时将进行验证。默认值为false。org.quartz.dataSource.NAME.discardIdleConnectionsSeconds它们在空闲之后放弃连接几秒钟。0禁用该功能。默认值为0。 参考资料https://www.w3cschool.cn/quartz_doc/quartz_doc-d8pn2do9.html]]></content>
      <categories>
        <category>quartz</category>
      </categories>
      <tags>
        <tag>后端</tag>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python笔记]]></title>
    <url>%2F2018%2F05%2Fpython%2Fpython%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[python笔记python之蝉解释器中输入import thisNow is better than never. String大写name.upper()小写name.lower()首字母大写name.title()使用+拼接字符串去掉空格strip()，lstrip()，rstrip()将非字符串值表示为字符串str() 数字在python2和python3中除的结果不一样123/2=1 #python23/2=1.5 #python3 列表索引为负数时列表倒数，索引-1返回最后一个元素追加元素list.append(xx)插入元素list.instert(2,xx)删除元素 del list(2)弹出元素 list.pop(),list.pop(2)根据值删除 list.pop(‘lisi’)排序 list.sort()临时排序 list.sorted()反转顺序 list.reverse()长度 list.len()生成数值数组函数range()列表解析1squares = [value** 2 for value in range( 1,11)] 遍历for item in list: 切片列表的部分元素切片复制12my_foods = [&apos; pizza&apos;, &apos;falafel&apos;, &apos;carrot cake&apos;] friend_foods = my_foods[:] 元组Python将不能修改的值称为不可变的，而不可变的列表被称为元组。元组不可以改变元素，但是可以重新定义元组。定义元组使用圆括号 for 遍历123for item in list: for k, v in map.items(): if123456if true : ...elif: ...else: ... 检查多个条件使用and，or检测元素是否在列表中 if item in list: ,if item not in list: while在列表之间移动元素 while list:判断列表包含某个元素 while ‘aa’ in list: 获取输入python2 raw_input()python3 input() 字典字典是一系列键值对，用放在花括号{}中的一系列键—值对表示删除元素 del userMap[‘name’]遍历字典键值 for k, v in map.items():遍历字典中所有建 for name in favorite_languages.keys():遍历字典中所有的值 for language in favorite_languages.values(): 函数定义函数使用 def实参和形参位置实参，关键字实参，默认值在函数中对这个列表所做的任何修改都是永久性的禁止函数修改列表，将列表的副本传递给函数 list[:]，用切片创建副本传递任意数量的实参，形参名toppings中的星号让python创建一个名为toppings的空元组，将收到的值都封装到这个元组中。形参*user_info中的两个星号让Python创建一个名为user_info的空字典，并将收到的所有名称—值对都封装到这个字典中。 导入函数导入整个模块 import module_name导入模块特定函数 from module_name import function_name1,function_name2使用as给函数指定别名 from module_name import function_name1 as name1使用as给模块指定别名 import module_name as m1导入模块全部函数 from module_name import * 类关键字 class 定义类创建类dog.py12345678910111213class Dog(): &quot;&quot;&quot; 一 次 模 拟 小 狗 的 简 单 尝 试&quot;&quot;&quot; def __init__( self, name, age): &quot;&quot;&quot; 初 始 化 属 性 name 和 age&quot;&quot;&quot; self.name = name self.age = age def sit( self): &quot;&quot;&quot; 模 拟 小 狗 被 命 令 时 蹲 下&quot;&quot;&quot; print( self.name.title() + &quot; is now sitting.&quot;) def roll_over( self): &quot;&quot;&quot; 模 拟 小 狗 被 命 令 时 打 滚&quot;&quot;&quot; print( self.name.title() + &quot; rolled over!&quot;) 方法init()，创建实例时会自动运行，这个方法的定义中，形参self必不可少，还必须位于其他形参的前面。创建实例时，将自动传入实参self。每个与类相关联的方法调用都自动传递实参self，它是一个指向实例本身的引用，让实例能够访问类中的属性和方法。以self为前缀的变量都可供类中的所有方法使用 创建类实例1my_dog=Dog(&apos;wille&apos;,6) 类的继承一个类继承另外一个类时，它将自动获得另一个类的所有属性和方法。创建子类时，父类必须包含在当前文件中，且位于子类前面。定义子类时，必须在括号内指定父类的名称。 文件12with open(&apos;pi_digits.txt&apos;) as file_obj: contents=file_obj.read() with可以妥善管理打开和关闭 异常12345678try:&lt;语句&gt; #运行别的代码except &lt;名字&gt;：&lt;语句&gt; #如果在try部份引发了&apos;name&apos;异常except &lt;名字&gt;，&lt;数据&gt;:&lt;语句&gt; #如果引发了&apos;name&apos;异常，获得附加的数据else:&lt;语句&gt; #如果没有异常发生 存储数据json.dump(),json.load()123456789numbers =[2,3,5,7]filename=&apos;jsondump.txt&apos;with open(filename,&apos;w&apos;) as file_obj: json.dump(numbers,file_obj)filename=&apos;jsondump.txt&apos;with open(filename,&apos;r&apos;) as file_obj: numbers=json.load(numbers,file_obj)print(numbers) 测试代码1234567import unittestclass TestDict(unittest.TestCase): def test_init(self): d = Dict(a=1, b=&apos;test&apos;) self.assertEqual(d.a, 1) self.assertEqual(d.b, &apos;test&apos;) self.assertTrue(isinstance(d, dict)) pygamelinux安装12345安装 pygamepip install pygamehg clone https://bitbucket.org/pygame/pygamepython3 setup.py buildsudo python3 setup.py install mac安装1234brew install hd sdl sdl_image sdl_ttfbrew install sdl_mixer portmidi # 声音# pip3 install hg+http://bitbucket.org/pygame/pygamepip3 install pygame 帮助文档使用pydoc查看pydoc keywordpydoc3 keyword 查询模块的使用方法 命令模式输入help()，然后输入关键字 命令模式输入help(str),help(str.split)quit退出123456789101112131415161718Help on class str in module builtins:class str(object) | str(object=&apos;&apos;) -&gt; str | str(bytes_or_buffer[, encoding[, errors]]) -&gt; str | | Create a new string object from the given object. If encoding or | errors is specified, then the object must expose a data buffer | that will be decoded using the given encoding and error handler. | Otherwise, returns the result of object.__str__() (if defined) | or repr(object). | encoding defaults to sys.getdefaultencoding(). | errors defaults to &apos;strict&apos;. | | Methods defined here: | | __add__(self, value, /) ... ... 查看模块下所有函数dir(module_name)，如12&gt;&gt;&gt; dir(str)[&apos;__add__&apos;, &apos;__class__&apos;, &apos;__contains__&apos;, &apos;__delattr__&apos;, &apos;__dir__&apos;, &apos;__doc__&apos;, &apos;__eq__&apos;, &apos;__format__&apos;, &apos;__ge__&apos;, &apos;__getattribute__&apos;, &apos;__getitem__&apos;, &apos;__getnewargs__&apos;, &apos;__gt__&apos;, &apos;__hash__&apos;, &apos;__init__&apos;, &apos;__init_subclass__&apos;, &apos;__iter__&apos;, &apos;__le__&apos;, &apos;__len__&apos;, &apos;__lt__&apos;, &apos;__mod__&apos;, &apos;__mul__&apos;, &apos;__ne__&apos;, &apos;__new__&apos;, &apos;__reduce__&apos;, &apos;__reduce_ex__&apos;, &apos;__repr__&apos;, &apos;__rmod__&apos;, &apos;__rmul__&apos;, &apos;__setattr__&apos;, &apos;__sizeof__&apos;, &apos;__str__&apos;, &apos;__subclasshook__&apos;, &apos;capitalize&apos;, &apos;casefold&apos;, &apos;center&apos;, &apos;count&apos;, &apos;encode&apos;, &apos;endswith&apos;, &apos;expandtabs&apos;, &apos;find&apos;, &apos;format&apos;, &apos;format_map&apos;, &apos;index&apos;, &apos;isalnum&apos;, &apos;isalpha&apos;, &apos;isdecimal&apos;, &apos;isdigit&apos;, &apos;isidentifier&apos;, &apos;islower&apos;, &apos;isnumeric&apos;, &apos;isprintable&apos;, &apos;isspace&apos;, &apos;istitle&apos;, &apos;isupper&apos;, &apos;join&apos;, &apos;ljust&apos;, &apos;lower&apos;, &apos;lstrip&apos;, &apos;maketrans&apos;, &apos;partition&apos;, &apos;replace&apos;, &apos;rfind&apos;, &apos;rindex&apos;, &apos;rjust&apos;, &apos;rpartition&apos;, &apos;rsplit&apos;, &apos;rstrip&apos;, &apos;split&apos;, &apos;splitlines&apos;, &apos;startswith&apos;, &apos;strip&apos;, &apos;swapcase&apos;, &apos;title&apos;, &apos;translate&apos;, &apos;upper&apos;, &apos;zfill&apos;] 查看对象某个属性的帮助文档，如要查看str的split属性，可以用doc，print(str.split.doc)12345678&gt;&gt;&gt; print(str.split.__doc__)S.split(sep=None, maxsplit=-1) -&gt; list of stringsReturn a list of the words in S, using sep as thedelimiter string. If maxsplit is given, at most maxsplitsplits are done. If sep is not specified or is None, anywhitespace string is a separator and empty strings areremoved from the result. 分界符python的分界符是冒号和缩进 一切都是对象 异常 name如果导入一个模块，那么这个模块的name就是这个模块的文件名，如果直接运行这个模块，那么name就是main。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim使用（2）编辑]]></title>
    <url>%2F2018%2F05%2Fvim%2Fvim%E4%BD%BF%E7%94%A8%EF%BC%882%EF%BC%89%E7%BC%96%E8%BE%91%2F</url>
    <content type="text"><![CDATA[窗口 创建窗口 12345678910水平分割窗口:split 当前窗口一分为二，两个窗口显示相同内容。 :10split 新窗口的高度10行:split otherfile 新窗口中打开otherfile :new 功能和split一样 :sp split的缩写形式 ctrl+w+s 分割窗口的快捷方式垂直分割窗口:vsplit 以上所有命令都适用于打开垂直分割窗口，只要在前面加v(vetical) 关闭窗口 1234q 或 close #关闭当前窗口 only #保留当前窗口，关闭其它所有窗口 qall(qa) #退出所有窗口 wall #保存所有窗口 窗口切换:ctrl+w+j/k，通过j/k可以上下切换，或者:ctrl+w加上下左右键，还可以通过快速双击ctrl+w依次切换窗口。 窗口大小调整 12345678910纵向调整:ctrl+w + 纵向扩大（行数增加）:ctrl+w - 纵向缩小 （行数减少）:res(ize) num 例如：:res 5，显示行数调整为5行:res(ize)+num 把当前窗口高度增加num行:res(ize)-num 把当前窗口高度减少num行横向调整:vertical res(ize) num 指定当前窗口为num列:vertical res(ize)+num 把当前窗口增加num列:vertical res(ize)-num 把当前窗口减少num列 窗口重命名:f file 文件浏览 123:Ex 开启目录浏览器，可以浏览当前目录下的所有文件，并可以选择:Sex 水平分割当前窗口，并在一个窗口中开启目录浏览器:ls 显示当前buffer情况 vi与shell切换 12:shell 可以在不关闭vi的情况下切换到shell命令行:exit 从shell回到vi 页签1234567891011:tabnew [++opt选项] ［＋cmd］ 文件 建立对指定文件新的tabta:tab &lt;文件&gt; 新页签打开指定文件:tabc 关闭当前的tab:tabo 关闭所有其他的tab:tabs 查看所有打开的tab:tabp 前一个:tabn 后一个标准模式下：gt , gT 可以直接在tab之间切换。ngt 切换到指定的窗口。更多可以查看帮助 :help table ， help -p 编译运行vim 环境下，在命令模式中输入下命令：1:!python % NERDTree命令安装git clone https://github.com/scrooloose/nerdtree.git ~/.vim/bundle :h NERDTree 查看帮助文档 12345678910111213141516171819202122232425262728293031323334353637383940414243444546? 查看所有命令窗口切换ctrl + w + h 光标移动到左侧树形目录ctrl + w + l 光标移动到右侧文件显示窗口ctrl + w + w 光标自动在左右侧窗口切换ctrl + w + r 移动当前窗口的布局位置打开文件o 在已有窗口中打开文件、目录或书签，并跳到该窗口go 在已有窗口 中打开文件、目录或书签，但不跳到该窗口t 在新 Tab 中打开选中文件/书签，并跳到新 TabT 在新 Tab 中打开选中文件/书签，但不跳到新 Tabi split 一个新窗口打开选中文件，并跳到该窗口gi split 一个新窗口打开选中文件，但不跳到该窗口s vsplit 一个新窗口打开选中文件，并跳到该窗口gs vsplit 一个新 窗口打开选中文件，但不跳到该窗口! 执行当前文件O 递归打开选中 结点下的所有目录x 合拢选中结点的父目录D 删除当前书签P 跳到根结点p 跳到父结点K 跳到当前目录下同级的第一个结点J 跳到当前目录下同级的最后一个结点k 跳到当前目录下同级的前一个结点j 跳到当前目录下同级的后一个结点C 将选中目录或选中文件的父目录设为根结点u 将当前根结点的父目录设为根目录，并变成合拢原根结点U 将当前根结点的父目录设为根目录，但保持展开原根结点r 递归刷新选中目录R 递归刷新根结点m 显示文件系统菜单cd 将 CWD 设为选中目录I 切换是否显示隐藏文件f 切换是否使用文件过滤器F 切换是否显示文件B 切换是否显示书签A 全屏显示开关q 关闭 NerdTree 窗口:NERDTreeToggle 打开 NerdTree 窗口 vimrc1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&quot; *********************************************&quot; Vbundle插件管理&quot; *********************************************set nocompatible &quot; requiredfiletype off &quot; required&quot; set the runtime path to include Vundle and initializeset rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin()&quot; alternatively, pass a path where Vundle should install plugins&quot;call vundle#begin(&apos;~/some/path/here&apos;)&quot; let Vundle manage Vundle, requiredPlugin &apos;gmarik/Vundle.vim&apos;Plugin &apos;scrooloose/nerdtree&apos;Plugin &apos;majutsushi/tagbar&apos;Plugin &apos;vim-scripts/indentpython.vim&apos;&quot; Add all your plugins here (note older versions of Vundle used Bundle instead of Plugin)&quot; All of your Plugins must be added before the following linecall vundle#end() &quot; requiredfiletype plugin indent on &quot; required&quot; *********************************************&quot; 分割布局相关&quot; *********************************************set splitbelowset splitright&quot;快捷键，ctrl+l切换到左边布局，ctrl+h切换到右边布局&quot;ctrl+k切换到上面布局，ctrl+j切换到下面布局nnoremap &lt;C-J&gt; &lt;C-W&gt;&lt;C-J&gt;nnoremap &lt;C-K&gt; &lt;C-W&gt;&lt;C-K&gt;nnoremap &lt;C-L&gt; &lt;C-W&gt;&lt;C-L&gt;nnoremap &lt;C-H&gt; &lt;C-W&gt;&lt;C-H&gt;&quot; 开启代码折叠功能&quot; 根据当前代码行的缩进来进行代码折叠set foldmethod=indentset foldlevel=99&quot; *********************************************&quot; NERD插件属性&quot; *********************************************au vimenter * NERDTree &quot; 开启vim的时候默认开启NERDTreemap &lt;F2&gt; :NERDTreeToggle&lt;CR&gt; &quot; 设置F2为开启NERDTree的快捷键&quot; tagbar 启动时自动focuslet g:tagbar_auto_faocus =1&quot; 启动指定文件时自动开启tagbarautocmd BufReadPost *.cpp,*.c,*.h,*.hpp,*.cc,*.cxx call tagbar#autoopen()&quot; *********************************************&quot; python代码风格PEP8&quot; *********************************************au BufNewFile,BufRead *.py set tabstop=4 |set softtabstop=4|set shiftwidth=4|set textwidth=79|set expandtab|set autoindent|set fileformat=unixau BufNewFile,BufRead *.js, *.html, *.css set tabstop=2|set softtabstop=2|set shiftwidth=2]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中venv，pyvenv，pyenv，virtualenv，virtualenvwrapper，pipenv等有什么区别]]></title>
    <url>%2F2018%2F05%2Fpython%2Fpython%E4%B8%ADvenv%EF%BC%8Cpyvenv%EF%BC%8Cpyenv%EF%BC%8Cvirtualenv%EF%BC%8Cvirtualenvwrapper%EF%BC%8Cpipenv%E7%AD%89%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[PyPI软件包不在标准库中： virtualenv是一个非常受欢迎的工具，为Python库创建了孤立的Python环境。 如果您不熟悉此工具，我强烈建议您学习它，因为它是非常有用的工具，我将在此答案的其余部分进行比较。 它通过在目录（例如： env/ ）中安装一堆文件，然后修改PATH环境变量以将其前缀到自定义bin目录（例如： env/bin/ ）。 python或python3二进制文件的完整副本放置在此目录中，但Python被编程为首先在环境目录中查找相对于其路径的库。 它不是Python标准库的一部分，但是由PyPA（Python Packaging Authority）正式获得祝福。 激活后，您可以使用pip在虚拟环境中安装软件包。 pyenv用于隔离Python版本。 例如，您可能希望根据Python 2.6,2.7,3.3,3.4和3.5测试代码，因此您需要一种在它们之间切换的方法。 一旦被激活，它将在PATH环境变量~/.pyenv/shims加上~/.pyenv/shims ，其中有与Python命令（ python ， pip ）匹配的特殊文件。 这些不是Python发出的命令的副本; 它们是基于PYENV_VERSION环境变量或.python-version文件或~/.pyenv/version文件运行的Python版本的特殊脚本。 pyenv也使得使用命令pyenv install更容易地下载和安装多个Python版本的过程。 pyenv-virtualenv是与pyenv相同的作者pyenv的插件，可以方便地同时使用pyenv和virtualenv 。 但是，如果您使用的是Python 3.3或更高版本， pyenv-virtualenv将尝试运行python -m venv如果可用），而不是virtualenv 。 如果您不想要方便的功能，您可以在不使用pyenv-virtualenv情况下使用virtualenv和pyenv 。 virtualenvwrapper是一组对virtualenv的扩展（请参阅docs ）。 它给你的命令像mkvirtualenv ， lssitepackages ，特别是在不同的virtualenv目录之间切换的工作。 如果您想要多个virtualenv目录，此工具特别有用。 pyenv-virtualenvwrapper是与pyenv相同的作者的pyenv ，方便地将virtualenvwrapper集成到pyenv 。 pipenv ，Kenneth Reitz（ requests的作者），是一个全新的（可能是实验性的）项目，旨在将Pipfile，pip和virtualenv组合成一个命令行命令。 标准库： pyvenv是Python 3附带的一个脚本，但是在Python 3.6中已经弃用，因为它有问题（更不用说混淆的名字）。 在Python 3.6+中，完全相同的是python3 -m venv 。 venv是Python 3附带的软件包，您可以使用python3 -m venv运行（尽管某些原因有些发行版将其分离成独立的发行版包，如Ubuntu / Debian中的python3-venv ）。 它为virtualenv提供了类似的目的，并以非常类似的方式工作，但它不需要复制Python二进制文件（Windows除外）。 如果您不需要支持Python 2，请使用此功能。在撰写本文时，Python社区似乎对virtualenv感到满意，我没有听说过venv 。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>后端</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中long型string型ip地址转换]]></title>
    <url>%2F2018%2F05%2FJava%2Fjava%E4%B8%ADlong%E5%9E%8Bstring%E5%9E%8Bip%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class IPConvertor &#123; /** * long转ip地址，大端（高位字节放在低地址端） * @param ip * @return */ public static String numToIPBigEndian(long ip) &#123; StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt;= 3; i++) &#123; sb.append((ip &gt;&gt;&gt; (i * 8)) &amp; 0x000000ff); if (i != 3) &#123; sb.append(&apos;.&apos;); &#125; &#125; return sb.toString(); &#125; /** * long转ip地址，小端（低位字节放在低地址端） * @param ip * @return */ public static String numToIPLittleEndian(long ip) &#123; StringBuilder sb = new StringBuilder(); for (int i = 3; i &gt;= 0; i--) &#123; sb.append((ip &gt;&gt;&gt; (i * 8)) &amp; 0x000000ff); if (i != 0) &#123; sb.append(&apos;.&apos;); &#125; &#125; return sb.toString(); &#125; public static long ipToNumLittle(String ip) &#123; long num = 0; String[] sections = ip.split(&quot;\\.&quot;); int i = 3; for (String str : sections) &#123; num += (Long.parseLong(str) &lt;&lt; (i * 8)); i--; &#125; return num; &#125; // public static void main(String[] args) &#123; // long ip =571108042; // String numToIPBigEndian = numToIPBigEndian(ip); // System.out.println(numToIPBigEndian); // System.out.println(numToIPBigEndian(1338832698)); // System.out.println(numToIPBigEndian(1624045370)); // System.out.println(numToIPBigEndian(1725232954)); // &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EFK的索引清理]]></title>
    <url>%2F2018%2F05%2FELK%2FEFK%E7%9A%84%E7%B4%A2%E5%BC%95%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[近发现elasticsearch近期索引文件大的吓人，清理了下之前的索引文件，发现服务器性能大大的减轻了一半，想一直保留近一个月的索引文件，但是又不想每个月手动清楚，在此写了一个小脚本 一、 手动删除1rm -rf *2016-07-* 二、api删除 1curl -XDELETE &apos;http://127.0.0.1:9200/logstash-2017-10-*&apos; 清理掉了所有 7月份的索引文件，我发现curl 删除比rm删除要快出很多 三、脚本加api删除（推荐） 1234567cat es-index-clear.sh#/bin/bash#es-index-clear#获取上个月份日期LAST_DATA=`date -d &quot;last month&quot;+%Y-%m`#删除上个月份所有的索引curl -XDELETE&apos;http://127.0.0.1:9200/*-&apos;$&#123;LAST_DATA&#125;&apos;-*&apos; 四、添加到任务计划12crontab -e0 1 5 * * /script/es-index-clear.sh]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志系统</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python安装使用]]></title>
    <url>%2F2018%2F05%2Fpython%2Fpython%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[python安装12brew search pythonbrew install python3 Setuptools &amp; Pipsetuptools 和 pip 是最重要的两个Python第三方软件包。一旦安装了它们，就可以通过一条指令下载、安装和卸载可获取到的 Python应用包，还可以轻松地将这种网络安装的方式加入到自己开发的Python应用中。Python 2.7.9 以及之后版本(Python2 系列)，和Python 3.4以及之后版本均默认包含pip。运行以下命令行代码检查pip是否已经安装：1$ command -v pip pip 用于Python 2的，而 pip3 用于Python 3。1$ command -v pip3 安装方法123456curl安装curl https://bootstrap.pypa.io/get-pip.py -o get-pip.pypython get-pip.pyyum 安装yum -y install python-pip Pipenv安装Pipenv 是一个 Python 项目依赖管理工具，如果你熟悉 Node.js 的 npm 或者 Ruby 的 bundler ，他们是和 Pipenv 非常相似的工具。尽管 pip 也可以安装 Python 的包，但是 Pipenv 被推荐的理由是因为 Pipenv 为使用者提供了更加方便的依赖管理。虚拟环境是保持项目依赖独立的一种方式，Pipenv 是实现这种方式的其中一个工具，同时 Pipenv 也是一个依赖管理工具，也就是说 Pipenv 集成了 pip 和 virtual environment 的功能，通过创建虚拟环境，可以保证项目之间的的依赖互不干扰。 pip 安装 Pipenv ：1$ pip install --user pipenv 通过运行 python -m site –user-base 找到 用户基础目录，然后把 bin 加到目录末尾。通过 修改 ~/.profile 永久地设置 PATH。 virtualenvvirtualenv 是一个创建独立的 Python 环境。 virtualenv 会创建一个文件夹，其中包含使用 Python 项目所有所需的可执行文件。它可以单独使用，用于代替 Pipenv 。pip 安装 virtualenv ：12$ pip3 install virtualenv$ virtualenv --version 为项目创建一个虚拟环境：12$ cd my_project_folder$ virtualenv my_project virtualenv my_project 将会在当前目录创建一个文件夹来存放 Python 的可执行文件以及拷贝一份 pip 库，这样就能安装其他包了。 开始使用虚拟环境前，需要先激活：1$ source my_project/bin/activate 你所添加的扩展和运行的环境， 都处于这个隔离环境中了， 如果还需要一个python3.5的环境， 你可以在安装好python3.5（不要在任何隔离环境中）后， 创建隔离环境时，指定python版本即可12virtualenv -p python3.5 py3.5virtualenv -p /usr/bin/python2.7 my_project 如果你在虚拟环境中暂时完成了工作，可以这样停用它：1$ deactivate virtualenvwrappervirtualenvwrapper 是virtualenv的一些列扩展，它提供了诸如 mkvirtualenv, lssitepackages 等命令行工具，特别是 workon 命令行工具，当你需要使用多个virtualenv目录时使用该工具特别方便。它把您所有的虚拟环境都放在一个地方。123$ pip install virtualenvwrapper$ export WORKON_HOME=~/Envs$ source /usr/local/bin/virtualenvwrapper.sh virtualenv-burrito使用 virtualenv-burrito ，你可以只要使用一条命令就将 virtualenv + virtualenvwrapper 环境搭建起来。 autoenv当您 cd 进入一个包含 .env 的目录中，就会 autoenv 自动激活那个环境。1$ brew install autoenv 资料http://pythonguidecn.readthedocs.io/zh/latest/dev/virtualenvs.html]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB数据库角色]]></title>
    <url>%2F2018%2F05%2FMongoDB%2FMongoDB%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A7%92%E8%89%B2%2F</url>
    <content type="text"><![CDATA[内建的角色数据库用户角色：read、readWrite;数据库管理角色：dbAdmin、dbOwner、userAdmin；集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager；备份恢复角色：backup、restore；所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase超级用户角色：root // 这里还有几个角色间接或直接提供了系统超级用户的访问（dbOwner 、userAdmin、userAdminAnyDatabase）内部角色：__system 1234567891011角色说明：Read：允许用户读取指定数据库readWrite：允许用户读写指定数据库dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profileuserAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。root：只在admin数据库中可用。超级账号，超级权限 资料https://www.jianshu.com/p/a4e94bb8a052https://docs.mongodb.com/manual/reference/built-in-roles/#built-in-roleshttps://link.jianshu.com/?t=https://docs.mongodb.com/manual/reference/configuration-options/]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker仓库Registry]]></title>
    <url>%2F2018%2F05%2FDocker%2Fdocker%E4%BB%93%E5%BA%93Registry%2F</url>
    <content type="text"><![CDATA[仓库Registry 方便保存和分发镜像，Docker Hub 是 Docker 公司维护的公共 Registry。用户可以将自己的镜像保存到 Docker Hub 免费的 repository 中。 Docker Hub 上注册一个账号https://hub.docker.com/ 登录注意使用docker id登录，不要使用邮箱登录。不然会报错 1Error response from daemon: Get https://registry-1.docker.io/v2/: unauthorized: incorrect username or password docker tag 命令重命名镜像 1docker tag centos-vim-f 842071912/centos-vim-f:v1 docker push 842071912/centos-vim-f docker pull 拉取镜像]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB安装使用]]></title>
    <url>%2F2018%2F05%2FMongoDB%2FMongoDB%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[MongoDBMongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。 MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。 安装vim /etc/yum.repos.d/mongodb-org-3.6.repo123456[mongodb-org-3.6][mongodb-org-3.6] namename==MongoDB RepositoryMongoDB Repository baseurlbaseurl==https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/https://repo.mongodb.org/yum/redha gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc 修改数据文件存储位置vim /etc/mongod.conf 中的dbPath 123yum install -y mongodb-orgmongod #启动 3.6.4 启动 service mongod startmongo #进入命令行交互 开启认证 MongoDB是没有默认管理员账号，所以要先添加管理员账号，再开启权限认证。 切换到admin数据库，添加的账号才是管理员账号。 用户只能在用户所在数据库登录，包括管理员账号。 管理员可以管理所有数据库，但是不能直接管理其他数据库，要先在admin数据库认证后才可以1234567891011121314151617181920212223242526use admin// 创建用户db.createUser( &#123; user: &quot;admin&quot;, pwd: &quot;admin&quot;, roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125; ] &#125;)// 删除用户db.dropUser(用户名);// 查看用户权限db.runCommand( &#123; usersInfo:&quot;fastschooladmin&quot;, showPrivileges:true &#125;)// 查看当前用户db.runCommand(&#123;connectionStatus : 1&#125;)// 修改用户密码db.changeUserPassword(用户名, 新密码); 修改文件vim /etc/mongod.conf12security: authorization: enabled 重启mongod 修改提示信息123456789You can also add the user name to prompt by overriding the prompt function in .mongorc.js file, under OS user home directory. Roughly:prompt = function() &#123; user = db.runCommand(&#123;connectionStatus : 1&#125;).authInfo.authenticatedUsers[0] if (user) &#123; return &quot;user: &quot; + user.user + &quot;&gt;&quot; &#125; return &quot;&gt;&quot;&#125; 基本命令数据库 show dbs显示数据库列表 db 显示当前数据库对象或集合 use local 切换数据库，如果数据库不存在，则创建数据库，否则切换到指定数据库。如果刚创建的数据库在show dbs看不到，需要先插入数据才能看到。 db.dropDatabase() 删除数据库 集合 show tables 查看集合 db.createCollection(name, options) 创建集合或者当你插入一些文档时，MongoDB 会自动创建集合。 db.集合名.drop() 删除集合 文档 db.COLLECTION_NAME.insert(document) 插入文档 update() 和 save() 方法来更新集合中的文档 12345query : update的查询条件，类似sql update查询内where后面的。update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。writeConcern :可选，抛出异常的级别。 db.集合名.remove() 删除 1234567db.collection.remove( &lt;query&gt;, &#123; justOne: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) 参数说明：query :（可选）删除的文档的条件。justOne : （可选）如果设为 true 或 1，则只删除一个文档。writeConcern :（可选）抛出异常的级别。 删除所有数据：db.col.remove({}) db.集合名.find(query, projection)参数说明：query ：可选，使用查询操作符指定查询条件projection ：可选，使用投影操作符指定返回的键。查询时返回文档中所有键值， 只需省略该参数即可（默认省略）。 以易读格式输出db.col.find().pretty() 123456等于 &#123;&lt;key&gt;:&lt;value&gt;&#125;小于 &#123;&lt;key&gt;:&#123;$lt:&lt;value&gt;&#125;&#125; 小于或等于 &#123;&lt;key&gt;:&#123;$lte:&lt;value&gt;&#125;&#125;大于 &#123;&lt;key&gt;:&#123;$gt:&lt;value&gt;&#125;&#125;大于或等于 &#123;&lt;key&gt;:&#123;$gte:&lt;value&gt;&#125;&#125;不等于 &#123;&lt;key&gt;:&#123;$ne:&lt;value&gt;&#125;&#125; AND 条件db.col.find({key1:value1, key2:value2}).pretty() OR 条件db.col.find({$or: [{key1: value1}, {key2:value2}).pretty() limit()指定数量的数据记录 sort() 排序 ensureIndex()db.COLLECTION_NAME.ensureIndex({KEY:1})1为指定按升序创建索引，如果你想按降序来创建索引指定为-1即可 aggregate() 用于处理数据(诸如统计平均值,求和等)db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION) MongoDB时间少8小时自带的Date，时间是UTC的时间，和咱们中国时区少8个小时。使用Robomongo，可以通过”Options” - “Display Dates in…” - “Local Timezone”来设置显示本地时间。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker编写Dockerfile]]></title>
    <url>%2F2018%2F05%2FDocker%2Fdocker%E7%BC%96%E5%86%99Dockerfile%2F</url>
    <content type="text"><![CDATA[DockerfileDockerfile定义在container里有什么，Dockerfile 是一个包含创建镜像所有命令的文本文件，通过docker build命令可以根据 Dockerfile 的内容构建镜像。1234567891011121314指令选项:FROMMAINTAINERRUNCMDEXPOSEENVADDCOPYENTRYPOINTVOLUMEUSERWORKDIRONBUILD FROMFROM FROM指定构建镜像的基础源镜像，如果本地没有指定的镜像，则会自动从 Docker 的公共库 pull 镜像下来。FROM必须是 Dockerfile 中非注释行的第一个指令，即一个 Dockerfile 从FROM语句开始。FROM可以在一个 Dockerfile 中出现多次，如果有需求在一个 Dockerfile 中创建多个镜像。如果FROM语句没有指定镜像标签，则默认使用latest标。 MAINTAINERMAINTAINER 指定创建镜像的用户 RUNRUNRUN “executable”, “param1”, “param2”每条RUN指令将在当前镜像基础上执行指定命令，并提交为新的镜像，后续的RUN都在之前RUN提交后的镜像为基础，镜像是分层的，可以通过一个镜像的任何一个历史提交点来创建，类似源码的版本控制。 CMDCMD有三种使用方式: CMD “executable”,”param1”,”param2” CMD “param1”,”param2” CMD command param1 param2 (shell form)CMD的目的是为了在启动容器时提供一个默认的命令执行选项。如果用户启动容器时指定了运行的命令，则会覆盖掉CMD指定的命令。CMD会在启动容器的时候执行，build 时不执行，而RUN只是在构建镜像的时候执行，后续镜像构建完成之后，启动容器就与RUN无关了，这个。 EXPOSEEXPOSE […]告诉 Docker 服务端容器对外映射的本地端口，需要在 docker run 的时候使用-p或者-P选项生效。 ENVENV # 只能设置一个变量ENV = … # 允许一次设置多个变量指定一个环节变量，会被后续RUN指令使用，并在容器运行时保留。 ADDADD … ADD复制本地主机文件、目录或者远程文件 URLS 从 并且添加到容器指定路径中 。 COPYCOPY … COPY复制新文件或者目录从 并且添加到容器指定路径中 。用法同ADD，唯一的不同是不能指定远程文件 URLS。 ENTRYPOINTENTRYPOINT “executable”, “param1”, “param2”ENTRYPOINT command param1 param2 (shell form)配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖，而CMD是可以被覆盖的。如果需要覆盖，则可以使用docker run –entrypoint选项 VOLUMEVOLUME [“/data”]创建一个可以从本地主机或其他容器挂载的挂载点 USERUSER daemon指定运行容器时的用户名或 UID，后续的RUN、CMD、ENTRYPOINT也会使用指定用户。 WORKDIRWORKDIR /path/to/workdir为后续的RUN、CMD、ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。 ONBUILDONBUILD [INSTRUCTION]配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。 实例123456789# Version 0.1# 基础镜像FROM nbuntu:latest# 维护者信息MAINTAINER lihong/leehongitrd@163.com # 镜像操作命令RUN apt-get -yqq update &amp;&amp; apt-get install -yqq apache2 &amp;&amp; apt-get clean# 容器启动命令CMD [&quot;/usr/sbin/apache2ctl&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;] 上面的Dockerfile就做了一件事，即创建一个apache的镜像, FROM指定基础镜像，如果镜像名称中没有制定TAG, 默认为latest。 RUN命令默认使用/bin/sh Shell执行，默认为root权限。如果命令过长需要换行，需要在行末尾加\。 CMD 命令也是默认在/bin/sh Shell中执行，并且默认只能有一条，如果是多条CMD命令则只有最后一条执行。用户也可以在docker run命令创建容器时指定新的CMD命令来覆盖Dockerfile里的CMD。 用docker build将上述Dockerfile构建名为test:0.1的新镜像,1docker build -t test:0.1 . 使用该镜像创建容器web1, 将容器中的端口80映射到本地80端口,1docker run -d -p 80:80 --name web1 test:0.1]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装和使用]]></title>
    <url>%2F2018%2F05%2FDocker%2Fdocker%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[安装123# yum -y install docker# docker --versionDocker version 1.13.1, build 774336d/1.13.1 启动123456[root@VM_0_8_centos ~]# service docker startRedirecting to /bin/systemctl start docker.service[root@VM_0_8_centos ~]# docker info[root@VM_0_8_centos ~]# docker container --help 运行状态1[root@VM_0_8_centos ~]# service docker status hello-world1234567891011[root@VM_0_8_centos ~]# docker run hello-world[root@VM_0_8_centos ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/hello-world latest e38bc07ac18e 3 weeks ago 1.85 kB[root@VM_0_8_centos ~]# docker container ls --allCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES298b7dfcf12d hello-world &quot;/hello&quot; About a minute ago Exited (0) About a minute ago affectionate_williams docker run过程：1.首先本地查找2.本地没有，从Docker Hub或系统配置的默认Registry中下载 容器管理docker ps12345678910111213141516[root@VM_0_8_centos ~]# docker help psUsage: docker ps [OPTIONS]List containersOptions: -a, --all Show all containers (default shows just running) -f, --filter filter Filter output based on conditions provided --format string Pretty-print containers using a Go template --help Print usage -n, --last int Show n last created containers (includes all states) (default -1) -l, --latest Show the latest created container (includes all states) --no-trunc Don&apos;t truncate output -q, --quiet Only display numeric IDs -s, --size Display total file sizes 查看正在运行的容器docker psdocker container ls docker run如果我们需要一个保持运行的容器呢，最简单的方法就是给这个容器一个可以保持的应用，比如bash，运行 ubuntu 容器并进入容器的 bash123456789$ docker run -t -i ubuntu /bin/bash-t：分配一个 pseudo-TTY-i：--interactive参数缩写，表示交互模式，如果没有 attach 保持 STDIN 打开状态ubuntu：运行的镜像名称，默认为latest 标签/bin/bash：容器中运行的应用退出1. 直接 exit，这时候 bash 程序终止，容器进入到停止状态2. 使用组合键退出，仍然保持容器运行，我们可以随时回来到这个bash中来，组合键是 Ctrl-p Ctrl-q，你没有看错，是两组组合键，先同时按下Ctrl和p，再按Ctrl和q。就可以退出到我们的宿主机了。 docker run 命令实际上是 docker create 和 docker start 的组合。 1234567891011docker run --name nginx001 -idt -P -v /mnt/hgfs/common_dir:/usr/Downloads daocloud.io/library/nginx1下面来解释一下这一行命令:run 根据指定的镜像文件启动一个容器--name nginx001 启动后这个容器的名字-d: 后台运行，并返回ID，如果不加-d参数，那么容器运行会和终端绑定，如果终端关闭，那么容器也会关闭，但是容器不会被删除。但是如果你只是想试一试某个容器，运行后自动进入命令行，那么可以使用-it参数;如果你想容器关闭之后自动删除，那么就使用-rm参数。-i: 互模式运行容器-t: 为容器分配一个伪输入终端-P: docker容器和外侧的端口映射，随机映射一个端口至容器内部开放的网络端口-v 数据卷的挂载。这里涉及到docker container的一个特性，container如果停止运行了，那么再次启动时，之前所有运行相关的数据和文件就都不存在了。/mnt/hgfs/common_dir:/usr/Downloads：指定共享文件目录，进入容器后，容器的/usr/Downloads实际上就是ubuntu的/mnt/hgfs/common_dir目录了，这样传文件方便daocloud.io/library/nginx：镜像文件名称，就是刚才下载的那个 docker attach进入正在运行的容器可通过 Ctrl+p 然后 Ctrl+q 组合键退出 attach 终端。 docker execdocker exec 进入相同的容器12执行 exit 退出容器，回到 docker host。docker exec -it &lt;container&gt; bash|sh 是执行 exec 最常用的方式 attach VS execattach 与 exec 主要区别如下: attach 直接进入容器 启动命令 的终端，不会启动新的进程。 exec 则是在容器中打开新的终端，并且可以启动新的进程。 如果想直接在终端中查看启动命令的输出，用 attach；其他情况使用 exec。 如果只是为了查看启动命令的输出，可以使用 docker logs 命令，-f 的作用与 tail -f 类似，能够持续打印输出。 docker start启动容器 docker stop暂停一个或多个运行的容器 docker inspect查看 Docker 容器或镜像的一些内部信息 docker rm删除容器操作。不能删除运行的容器。一次可以指定多个容器，如果希望批量删除所有已经退出的容器，可以执行如下命令：docker rm -v $(docker ps -aq -f status=exited) 镜像管理docker images列出当前系统上所有的镜像信息 docker search搜索镜像 docker pull获取镜像 history显示镜像构建历史 tag给镜像打 tag Dockerfile 创建镜像制作镜像的方式主要有两种：通过docker commit 制作镜像docker commit 是往版本控制系统里提交一次变更。使用这种方式制作镜像，本质上是运行一个基础镜像，然后在基础镜像上进行软件安装和修改。最后再将改动提交到版本系统中。通过docker build 制作镜像使用docker build创建镜像需要编写Dockerfile.123451. 创建Dockerfile文件from ubuntu:latestENV HOSTNAME=shiyanlou2. 执行docker build -t 镜像名 Dockerfile文件目录3. 查看docker images docker inspect查看 Docker 容器或镜像的一些内部信息 docker rmi清理镜像 search搜索 Docker Hub 中的镜像 网络管理默认情况123Docker服务启动时会自动创建一个 docker0 的虚拟网桥，后续新创建的容器都会有个虚拟接口连接到这个网桥1. NAT模式2. 网址自动分配 配置文件123456789/etc/default/docker如果需要对网络进行配置，则需要对配置参数DOCKER_OPTS启动参数进行修改网络配置的相关参数1. -b --bridge ：指定连接的网桥2. --bip=CIDR：指定IP地址网段3. --icc=true|false：是否允许容器间网络互通4. --ip-forward=true|false：是否允许IP转发，可以对容器的外网访问进行限制 修改docker配置文件后需要重启docker服务 容器启动时网络参数设置1231. -h --hostname：配置容器主机名2. --link：添加另外一个容器的链接，见后续实验内容3. --net=bridge|none|container|host：设置容器的网络模式 限制容器访问外网限制容器访问外网，可以关闭IP转发，设置方法是启动Docker时–ip-forward=false。或sudo vim /etc/default/docker 修改配置文件 限制容器间的访问限制容器间的访问，可以设置–icc参数，或设置iptables参数。默认容器间可以互相访问，通过设置–icc=false可以禁止。 Docker 容器端口映射docker run -ti -p 80:80 -p 5000:5000 –name shiyanlou3 ubuntu宿主机端口:容器端口如果想映射到指定的本地地址，可以增加IP参数，比如映射到127.0.0.1地址，只需要将参数写成 -p 127.0.0.1:80:80。docker port 容器名查看端口映射情况 Docker 容器互联123docker run -d --name db redisdocker run -ti --nam app --link db:db shiyanloutest:1.0 /bin/bashdocker run -ti --name web --link app:app shiyanloutest:1.0 /bin/bash 通过link连接 数据卷的使用 使用docker create命令创建但不启动数据卷容器： 1docker create -v /shiyanloudata --name shiyanloudb ubuntu /bin/true 其他使用该数据卷容器的容器创建时候需要使用–volumes-from参数，指定该容器名称或ID： 1234docker run --volumes-from shiyanloudb ...#s1 s2容器中都将会有一个/shiyanloudata目录，二者是共享目录的docker run --volumes-from shiyanloudb --name s1 -t -i ubuntu /bin/bashdocker run --volumes-from shiyanloudb --name s1 -t -i ubuntu /bin/bash 备份数据卷1docker run --rm --volumes-from shiyanloudb -v /tmp/backup:/backup ubuntu tar cvf /backup/shiyanloudb.tar /shiyanloudata 命令解析 docker run –rm –volumes-from shiyanloudb 创建并在执行操作后移除容器 -v /tmp/backup:/backup 将创建的容器的backup目录挂载在宿主的/tmp/backupm目录 将数据卷 /shiyanloudata 的数据打包shiyanloudb.tar并存放到/backup/shiyanloudb.tar执行完上述命令，在宿主机的/tmp/backup/shiyanloudb.tar下将会有shiyanloudb.tar文件 资料Docker常见命令—简易教程：http://www.youruncloud.com/docker/1_37.htmlhttps://docs.docker.com/install/linux/docker-ce/centos/#os-requirementshttps://docs.docker.com/get-started/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux：ssh登录后闲置时间过长而断开连接]]></title>
    <url>%2F2018%2F05%2FLinux%2FLinux%EF%BC%9Assh%E7%99%BB%E5%BD%95%E5%90%8E%E9%97%B2%E7%BD%AE%E6%97%B6%E9%97%B4%E8%BF%87%E9%95%BF%E8%80%8C%E6%96%AD%E5%BC%80%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[ssh登录后闲置时间过长而断开连接终端ssh登录远程服务器长时间不操作服务器就会自动断开连接解决此问题的方法： 方法一： #vi /etc/ssh/sshd_config配置文件，修改为ClientAliveInterval 60，每分钟发送一次检测客户端是否连接 ，ClientAliveCountMax 3 服务器发出请求后客户端没有响应的次数达到一定值, 就自动断开 修改完成并保存后，执行命令：#service sshd reload使配置立即生效！ 方法二： 修改/etc/profile配置文件：#vi /etc/profile 增加：TMOUT=1800 这样30分钟没操作才自动LOGOUT]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令：pushd和popd]]></title>
    <url>%2F2018%2F05%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9Apushd%E5%92%8Cpopd%2F</url>
    <content type="text"><![CDATA[pushd和popdpushd 常用于将目录加入到栈中，加入记录到目录栈顶部，并切换到该目录popd 用于删除目录栈中的记录 使用1pushd /usr/local/xxxx &amp;&amp; git pull &amp;&amp; popd]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令：密钥创建]]></title>
    <url>%2F2018%2F05%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9A%E5%AF%86%E9%92%A5%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[ssh-keygenssh-keygen命令用于为“ssh”生成、管理和转换认证密钥，它支持RSA和DSA两种认证密钥。 12345678910111213语法ssh-keygen选项-b：指定密钥长度；-e：读取openssh的私钥或者公钥文件；-C：添加注释；-f：指定用来保存密钥的文件名；-i：读取未加密的ssh-v2兼容的私钥/公钥文件，然后在标准输出设备上显示openssh兼容的私钥/公钥；-l：显示公钥文件的指纹数据；-N：提供一个新密语；-P：提供（旧）密语；-q：静默模式；-t：指定要创建的密钥类型。 使用1ssh-keygen -t rsa -C &quot;xxxxx@xxxxx.com&quot;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git命令设置不提交更改文件]]></title>
    <url>%2F2018%2F04%2F%E5%B7%A5%E5%85%B7%2Fgit%E5%91%BD%E4%BB%A4%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E5%92%8C%E8%AE%BE%E7%BD%AE%E4%B8%8D%E6%8F%90%E4%BA%A4%E5%B7%B2%E6%9B%B4%E6%94%B9%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[git rm需要删除暂存区或分支上的文件, 同时工作区也不需要这个文件了1git rm file_path git rm –cache需要删除暂存区或分支上的文件, 但本地又需要使用, 只是不希望这个文件被版本控制,1git rm --cached file_path 删除之后加入.gitignoreps：.gitignore 只会对未加入版本控制的文件有效，如果已经加入过，需要从版本控制中移出 git update-index已经将这个文件提交到git库中,希望之后修改不再提交。 12345执行命令将file_path加入不提交队列git update-index --assume-unchanged file_path执行命令将xxx/xxx取消加入不提交队列git update-index --no-assume-unchanged file_path]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[域名下划线问题]]></title>
    <url>%2F2018%2F04%2F%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%2F%E5%9F%9F%E5%90%8D%E4%B8%8B%E5%88%92%E7%BA%BF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题1234567891011121314151617181920212223242526272829303132333435org.springframework.web.util.NestedServletException: Request processing failed; nested exception is java.lang.NullPointerException at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:980) at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:870) at javax.servlet.http.HttpServlet.service(HttpServlet.java:707) at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:844) at javax.servlet.http.HttpServlet.service(HttpServlet.java:790) at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:800) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1669) at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121) at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652) at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143) at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577) at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223) at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127) at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515) at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185) at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061) at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141) at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215) at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97) at org.eclipse.jetty.server.Server.handle(Server.java:497) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:245) at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635) at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555) at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.NullPointerException at org.springframework.web.util.WebUtils.isSameOrigin(WebUtils.java:816) at org.springframework.web.cors.DefaultCorsProcessor.processRequest(DefaultCorsProcessor.java:71) at org.springframework.web.servlet.handler.AbstractHandlerMapping$CorsInterceptor.preHandle(AbstractHandlerMapping.java:503) at org.springframework.web.servlet.HandlerExecutionChain.applyPreHandle(HandlerExecutionChain.java:134) 网上分析的原因12345678910可能原因：1、你用了4.2.5.RELEASE版本或者4.2.6.RELEASE，升级到4.2.7.RELEASE就好了。（我的就是这个原因）2、增加Nginx配置proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass_request_headers on; 但是我的情况没有解决，后来发现是域名不能使用下划线的原因]]></content>
      <categories>
        <category>问题记录</category>
      </categories>
      <tags>
        <tag>问题记录</tag>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令：crontab定时任务]]></title>
    <url>%2F2018%2F04%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9Acrontab%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Croncron其实是一个存放在/etc/init.d/下的一个脚本crond，随着系统开机自动启动，可以由service命令调度控制开启和关闭。 12345678[root@VM_152_30_centos ~]# ll /etc/init.d/total 236-rwxr-xr-x 1 root root 1818 Feb 17 2016 acpid-rwxr-xr-x 1 root root 2062 Feb 20 2015 atd-rwxr-xr-x 1 root root 3580 May 11 2016 auditd-r-xr-xr-x 1 root root 1343 Aug 24 2016 blk-availability-rw-r--r--. 1 root root 460 Dec 25 2014 bootlocal-rwxr-xr-x 1 root root 2826 Aug 24 2016 crond Step1首先，cron会搜索/var/spool/cron/文件夹，这个文件夹下有多个以用户名命名的文件，每个文件就是属于各个用户的独立的cron配置文件。123456[root@VM_152_30_centos ~]# cat /var/spool/cron/root#secu-tcs-agent monitor, install at Fri Apr 1 15:51:35 CST 2016* * * * * /usr/local/sa/agent/secu-tcs-agent-mon-safe.sh &gt; /dev/null 2&gt;&amp;1*/20 * * * * /usr/sbin/ntpdate ntpupdate.tencentyun.com &gt;/dev/null &amp;0 0 * * * /usr/sbin/logrotate -vf /etc/logrotate.d/nginx*/1 * * * * /usr/local/qcloud/stargate/admin/start.sh &gt; /dev/null 2&gt;&amp;1 &amp; Step2然后，cron会去搜索/etc/crontab文件，并且解析里面的cron配置12345678910111213141516[root@VM_152_30_centos ~]# cat /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootHOME=/# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed Step3最后，cron会去执行/etc/cron.d/这个文件夹下的东西，不过我们通常不建议在这里进行修改，虽然这个文件夹下的变化也会被监视，但是我们更习惯将这种不通用的定时任务配置在/etc/crontab/里。 Crontabcrontab其实是方便用户来维护crontab配置文件的工具,通过crontab -l可以显示属于当前用户的/var/spool/cron/文件夹下的配置。通过crontab -e可以安全的进行编辑，如果语法不对他会进行提示，保证安全。同时，crontab还提供了两个配置文件来控制用户的权限–/etc/cron.allow跟/etc/cron.deny。只有用户名在白名单里的用户才能使用crontab命令，用户名在黑名单里的用户是无法使用crontab命令的。显然，原则上这两个配置文件不能同时存在，如果同时存在，那么出于保守原则考虑，只有白名单有效，黑名单无效。如果这两个配置不存在，那么根据linux版本的不同，有的系统默认所有用户都有权限，有的系统默认只有root才有权限。 配置选择固定用户的定时任务我们就可以使用crontab -e命令去修改位于/var/spool/cron/下的属于当前用户的配置文件。这样就能够非常方便的区分不同用户的配置，保护了数据的安全。 固定时间的定时任务很多情况下，作为系统管理员，我们需求的任务模式大都是每小时触发，每日触发，每周触发，每月触发之类的。那么这时我们就可以不用配置cron项，只需要把脚本放在对应的/etc/cron.daily,/etc/cron.hourly之类的文件夹下即可，方便省事。而且事实上，很多系统自身需要的定时任务就是这么办的。这种方式也是我们最推荐的方式，因为我们只要把需要定时执行的脚本放在规定的路径下即可，无需配置cron，毕竟cron配置文件用起来还是比shell脚本麻烦很多。 固定程序的定时任务有时候，某些处理特定任务的进程也希望能够创建定时任务，比如我们编写或者安装的第三方任务。这些任务不希望依附于某一个用户，而希望拥有独立的配置文件，方便修改和卸载等等。这时候我们就可以新建一个cron配置文件，放置于/etc/cron.d/文件夹下，进行统一管理。像csf,lfd这类的进程就是这么做的，通过这样的配置保证服务定时重启。 资料http://www.cnblogs.com/peida/archive/2013/01/08/2850483.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java生成缩略图之Thumbnailator]]></title>
    <url>%2F2018%2F04%2FJava%2FJava%E7%94%9F%E6%88%90%E7%BC%A9%E7%95%A5%E5%9B%BE%E4%B9%8BThumbnailator%2F</url>
    <content type="text"><![CDATA[介绍Thumbnailator是个开源的Java 项目，它提供了非常简单流畅的 API 来对图片进行缩放、旋转、批量处理图片以及加水印的处理。 使用123Thumbnails.of(file.getInputStream()).scale(1.0).rotate(0) .outputQuality(0.5D).imageType(BufferedImage.TYPE_INT_ARGB) .toOutputStream(outputStream); 资料https://item.congci.com/-/content/thumbnailator-tupian-suofang-xuanzhuan-jia-shuiyin]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql-cpu占用过高解决方法]]></title>
    <url>%2F2018%2F04%2FMySql%2Fmysql-cpu%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[CPU报警：很可能是 SQL 里面有较多的计算导致的连接数超高：很可能是有慢查询，然后导致很多的查询在排队，排查问题的时候可以看到”事发现场“类似的 SQL 语句一大片，那么有可能是没有索引或者索引不好使，可以用：explain 分析一下 SQL 语句 查看事发现场 show processlist 语句，查找负荷最重的 SQL 语句，优化该SQL 开启慢查询，找到性能瓶颈点的SQL语句，然后使用explain，看看该语句是否可以优化； show [full] processlistshow [full] processlist 可以看到所有链接的情况观察有问题的链接12345-- 查询非 Sleep 状态的链接，按消耗时间倒序展示，自己加条件过滤select id, db, user, host, command, time, state, infofrom information_schema.processlistwhere command != &apos;Sleep&apos;order by time desc kill 使用123456-- 查询执行时间超过2分钟的线程，然后拼接成 kill 语句select concat(&apos;kill &apos;, id, &apos;;&apos;)from information_schema.processlistwhere command != &apos;Sleep&apos;and time &gt; 2*60order by time desc]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC 接收参数的几种方式]]></title>
    <url>%2F2018%2F03%2Fspring%E5%AE%B6%E6%97%8F%2FSpringMVC-%E6%8E%A5%E6%94%B6%E5%8F%82%E6%95%B0%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[注解1234A、处理requet uri 部分（这里指uri template中variable，不含queryString部分）的注解： @PathVariable;B、处理request header部分的注解： @RequestHeader, @CookieValue;C、处理request body部分的注解：@RequestParam, @RequestBody;D、处理attribute类型是注解： @SessionAttributes, @ModelAttribute; 接收Request uri中参数: @PathVariable 123@RequestMapping(&quot;/books/&#123;bookId&#125;&quot;) public void findPet(@PathVariable String userId, @PathVariable String bookId) &#123; &#125; 接收request header部分的注解: @RequestHeader,@CookieValue; 1234567891011@RequestMapping(&quot;/displayHeaderInfo.do&quot;) public void displayHeaderInfo(@RequestHeader(&quot;Accept-Encoding&quot;) String encoding, @RequestHeader(&quot;Keep-Alive&quot;) long keepAlive) &#123; &#125;@RequestMapping(&quot;/displayHeaderInfo.do&quot;) public void displayHeaderInfo(@CookieValue(&quot;JSESSIONID&quot;) String cookie) &#123; &#125; 接收request body部分的注解：@RequestParam,@RequestBody;@RequestParam使用场景：A)常用来处理简单类型的绑定，通过Reqeust.getParameter()获取的String可以直接转化为简单类型的情况；因为使用request.getParameter()方式获取参数，所以可以处理get方式中queryString的值，也可以获取Post方式中body data的值；B)用来处理Content-Type:为application/x-www-form-urlencoded编码的内容，提交方式GET、POST；C)该注解有两个属性：value、required;value用来指定要传入值得id名称，required用来指示参数是否必须绑定； @RequestBody作用：该注解常用来处理Content-Type:不是 application/x-www-form-urlencoded编码的内容，例如application/json,application/xml等； 它是通过HandlerAdapter配置的HttpMessageConverters来解析post data body，然后绑定到相应的bean上。 因为配置有FormHttpMessageConverter,所以也可以用来处理Application/x-www-form-urlencoded的内容，处理完的结果放在一个MultiValueMap里，这种情况特殊需求下使用，详情查看FormHttpMessageConverter api; 接收attribute类型的注解：@SessionAttributes,@ModelAttribute;@SessionAttributes:该注解用来绑定HttpSession中的attribute对象的值，便于在方法中的参数中使用。该注解有value、types两个属性，可以通过名字和类型指定要使用的attribute对象；123456@Controller @RequestMapping(&quot;/editPet.do&quot;) @SessionAttributes(&quot;pet&quot;) public class EditPetForm &#123; // ... &#125; @ModelAttribute该注解有两个用法：通常用来处理@RequestMapping之前，为请求绑定需要从后台查询的model；用于参数上时：用来通过名称对应，将相应名称的值绑定到注解的参数bean上；要绑定的值来源于：A)@SessionAttribute启用的attribute对象上；B)@ModelAttribute用于方法上时指定的model对象；C)上述两种情况都没有时，new一个需要绑定的bean对象，然后将request中按名称对应的方式把值绑定到bean中1234@ModelAttribute public Account addAccount(@RequestParam String number) &#123; return accountManager.findAccount(number); &#125; 这种方式实际的效果就是在调用@RequestMapping的方法之前，为request对象的model里put(“account”,Account); 用在参数上的@ModelAttribute示例代码：1234@RequestMapping(value=&quot;/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;/edit&quot;, method = RequestMethod.POST) public String processSubmit(@ModelAttribute Pet pet) &#123; &#125; 首先查询@SessionAttributes有无绑定的Pet对象，若没有则查询@ModelAttribute方法层面上是否绑定了Pet对象，若没有则URI template中的值按对应的名称绑定到Pet对象的各属性上。 form表单提交 直接参数名接收直接通过参数名接收，添加注解@RequestParam, 不添加注解时，参数名要和表单name一致，否则接收不到。 实体bean接收bean的属性要和表单name一致，可以不添加任何注解，也可以添加注解 @ModelAttribute,括号里的别名可以任意取，也可以不填 相同参数名可以用数组接收 123456@RequestMapping(value=&quot;/array/form/post/or/get&quot;,method=&#123;RequestMethod.POST,RequestMethod.GET&#125;) public void formPost(String[] userName,String testParam)&#123; logger.info(&quot;form表单提交，用数组接收相同参数名&quot;); logger.info(&quot;userName:&quot;+Arrays.toString(userName)); logger.info(&quot;testParam:&quot;+testParam); &#125; 链接请求 使用@PathVariable注解 使用@RequestParam注解这里和表单get请求一样 实体bean接收同表单提交一样 ajax请求 ajax请求,参数为json字符串,get请求用参数名获取json字符串，然后后台对json字符串做处理JSON.parseObject(json,class) ajax请求,参数为json字符串,post请求必须添加@RequestBody注解，利用spring框架将json串转成java bean,属性名称要和json字符串一致 ajax请求,post请求 json字符串直接用参数名获取注解@RequestBody，然后用String接收到整个json字符串 ajax发送数组格式的字符串数组格式的字符串，需要手动转换成数组对象 1234567891011121314/** * ajax发送数组格式的字符串， * 实际是数组格式的字符串，需要手动转换成数组对象 * @param params * @return */ @RequestMapping(value=&quot;/ajax/post/arr&quot;,method=RequestMethod.POST) public String ajaxPostArr(@RequestBody String params)&#123; logger.info(&quot;ajax传递数组格式的字符串&quot;); logger.info(&quot;params:&quot;+params); String[] arr = JSON.parseObject(params, String[].class); logger.info(Arrays.toString(arr)); return &quot;success&quot;; &#125; ajax直接传递数组对象，同时还可以传递其他参数 1234567891011121314151617/** * ajax直接传递数组对象，同时还可以传递其他参数， * 类似表单提交，注意要设置： * traditional：true * contentType:默认 * * @param params * @return */ @RequestMapping(value=&quot;/ajax/post/arr2&quot;,method=&#123;RequestMethod.POST,RequestMethod.GET&#125;) public String ajaxPostArr2(String[] params,String name)&#123; logger.info(&quot;ajax传递数组对象&quot;); logger.info(Arrays.toString(params)); logger.info(&quot;name:&quot;+name); return &quot;success&quot;; &#125; 后端POST方法接收参数实体bean接收，不添加任何注解,地址参数 ajax 请求,Content type’application/x-www-form-urlencoded;charset=UTF-8’,POST 实体bean接收，不添加任何注解,body传参 ContentType:x-www-form-urlencoded ajax 请求,Content type’application/x-www-form-urlencoded;charset=UTF-8’,POST 实体bean接收，使用@RequestBody注解 ajax 请求,Content type’application/json;charset=UTF-8’,POST 实体bean接收，使用@RequestBody注解 ajax 请求,Content type’application/json;charset=UTF-8’,POST, json.stringify 参考资料https://www.jianshu.com/p/b4b2c38d31eehttps://docs.spring.io/spring/docs/4.3.14.RELEASE/spring-framework-reference/htmlsingle/https://blog.csdn.net/MyNoteBlog/article/details/72519295]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>后端</tag>
        <tag>SpringMVC</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shiro简介]]></title>
    <url>%2F2018%2F03%2Fshiro%2Fshiro%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[什么是Apache Shiro？Apache Shiro 是一个强大易用的Java安全框架，提供了认证、授权、加密和会话管理功能，可为任何应用提供安全保障 - 从命令行应用、移动应用到大型网络及企业应用。 Shiro能做的事情 登录验证 访问控制，如： 判断用户是否拥有角色admin 判断用户是否拥有访问的权限 在任何环境下使用 Session API 可以使用多个用户数据源。例如一个是oracle用户库，另外一个是mysql用户库 单点登录（SSO）功能 “Remember Me”服务 ，类似购物车的功能，shiro官方建议开启 可以直接使用annotation对所使用的方法做权限控制 可以在jsp中通过shiro标签方便的做到细粒度的权限控制 四大API Authentication —— 认证，用户身份识别，常被称为用户“登录”，who are you? Authorization —— 授权，访问控制过程，决定“谁”访问“什么”，who can do what? Session Management —— 会话管理，用户session管理器，用户相关的时间敏感的状态 Cryptography —— 密码加密，把JDK中复杂的密码加密方式进行封装，保护或隐藏数据防止被偷窥]]></content>
      <categories>
        <category>shiro</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>shiro</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java List转换为树形结构数据]]></title>
    <url>%2F2018%2F03%2FJava%2Fjava-List%E8%BD%AC%E6%8D%A2%E4%B8%BA%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031/** * 转换为树形结构数据 * * @param authMenuVOList 列表数据 * @return 树形列表数据 */private List&lt;AuthMenuVO&gt; transListToTreeList(List&lt;AuthMenuVO&gt; authMenuVOList) &#123; List&lt;AuthMenuVO&gt; rootMenuList = Lists.newArrayList(); Map&lt;Long, AuthMenuVO&gt; menuNodeMap = Maps.newHashMap(); for (AuthMenuVO authMenuVO : authMenuVOList) &#123; menuNodeMap.put(authMenuVO.getId(), authMenuVO); &#125; //遍历列表数据，添加到父节点下，如果是根节点存入根节点列表中，如果不是根节点添加到父节点下 for (AuthMenuVO authMenuVO : authMenuVOList) &#123; Long pid = authMenuVO.getPid(); //判断是否是跟节点 if (pid == 0) &#123; rootMenuList.add(authMenuVO); &#125; else &#123; AuthMenuVO parentMenu = menuNodeMap.get(pid); List&lt;AuthMenuVO&gt; childrenList = parentMenu.getChildren(); if (childrenList == null) &#123; childrenList = Lists.newArrayList(); parentMenu.setChildren(childrenList); &#125; childrenList.add(authMenuVO); &#125; &#125; return rootMenuList;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>list</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode使用笔记]]></title>
    <url>%2F2018%2F03%2F%E5%B7%A5%E5%85%B7%2Fvscode%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[打开终端有三种方法可以唤出终端： 通过菜单 View | Toggle Integrated Terminal； 通过 Ctrl + Shift + P 从命令面板使用 View:Toggle Integrated Terminal； 快捷键 Ctrl+` 常用编辑器与窗口管理打开一个新窗口： Ctrl+Shift+N关闭窗口： Ctrl+Shift+W 文件新建文件 Ctrl+N历史打开文件之间切换 Ctrl+Tab，Alt+Left，Alt+Right切出一个新的编辑器（最多3个）Ctrl+\，也可以按住Ctrl鼠标点击Explorer里的文件名左中右3个编辑器的快捷键Ctrl+1 Ctrl+2 Ctrl+33个编辑器之间循环切换 Ctrl+`编辑器换位置，Ctrl+k然后按Left或Right 代码编辑代码行缩进Ctrl+[， Ctrl+]折叠打开代码块 Ctrl+Shift+[， Ctrl+Shift+]Ctrl+C Ctrl+V如果不选中，默认复制或剪切一整行代码格式化：Shift+Alt+F，或Ctrl+Shift+P后输入format code修剪空格Ctrl+Shift+X上下移动一行： Alt+Up 或 Alt+Down向上向下复制一行： Shift+Alt+Up或Shift+Alt+Down在当前行下边插入一行Ctrl+Enter在当前行上方插入一行Ctrl+Shift+Enter 光标相关移动到行首：Home移动到行尾：End移动到文件结尾：Ctrl+End移动到文件开头：Ctrl+Home移动到后半个括号 Ctrl+Shift+]选中当前行Ctrl+i（双击）选择从光标到行尾Shift+End选择从行首到光标处Shift+Home删除光标右侧的所有字Ctrl+DeleteShrink/expand selection： Shift+Alt+Left和Shift+Alt+RightMulti-Cursor：可以连续选择多处，然后一起修改，Alt+Click添加cursor或者Ctrl+Alt+Down 或 Ctrl+Alt+Up同时选中所有匹配的Ctrl+Shift+LCtrl+D下一个匹配的也被选中(被我自定义成删除当前行了，见下边Ctrl+Shift+K)回退上一个光标操作Ctrl+U 重构代码跳转到定义处：F12定义处缩略图：只看一眼而不跳转过去Alt+F12列出所有的引用：Shift+F12同时修改本文件中所有匹配的：Ctrl+F12重命名：比如要修改一个方法名，可以选中后按F2，输入新的名字，回车，会发现所有的文件都修改过了。跳转到下一个Error或Warning：当有多个错误时可以按F8逐个跳转查看diff 在explorer里选择文件右键 Set file to compare，然后需要对比的文件上右键选择Compare with ‘file_name_you_chose’. 查找替换查找 Ctrl+F查找替换 Ctrl+H整个文件夹中查找 Ctrl+Shift+F 显示相关全屏：F11zoomIn/zoomOut：Ctrl + =/Ctrl + -侧边栏显/隐：Ctrl+B预览markdown Ctrl+Shift+V]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的 JavaScript 库 CDN 加速服务]]></title>
    <url>%2F2018%2F03%2F%E5%89%8D%E7%AB%AF%2F%E5%B8%B8%E7%94%A8%E7%9A%84JavaScript%E5%BA%93CDN%E5%8A%A0%E9%80%9F%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[国内的公共库 百度CDN公共库：http://developer.baidu.com/wiki/index.php?title=docs/cplat/libs 百度静态资源公共库：http://cdn.code.baidu.com/ 新浪云计算CDN公共库：http://lib.sinaapp.com BootCDN公共库：http://www.bootcdn.cn 360公共库：http://libs.useso.com 七牛云存储 开放静态文件CDN：http://www.staticfile.org 又拍云JS库CDN服务：http://jscdn.upai.com 国外的公共库 CDNJS：http://www.cdnjs.com Google Hosted Libraries：https://developers.google.com/speed/libraries/ Microsoft ASP.net CDN：http://www.asp.net/ajaxlibrary/cdn.ashx jsDelivr：http://www.jsdelivr.com/]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[joda-time工具类]]></title>
    <url>%2F2017%2F12%2FJava%2Fjoda-time%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[数据初始化 日期差 格式化 日期计算 plus/minus 时间比较 isBefore/isAfter 官网 数据初始化12345DateTime dateTimeNow = new DateTime();DateTime dateTimeNow = new DateTime(date);//java日期转DateTimeDateTime recent = DateTime.parse(&quot;2017-05-18 17:40:00&quot;, DateTimeFormat.forPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;)); //字符串转日期DateTime dateTime2 = new DateTime(2017,2,14,0,0,0);//年月日时分秒DateTime dateTime = DateTimeFormat.forPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;).parseDateTime(&quot;2016-06-03 23:59:59&quot;); 日期差1234567DateTime dt1 = new DateTime();DateTime dt2 = new DateTime().plus();System.out.print(&quot;时间相差：&quot;);System.out.print(Days.daysBetween(dt1, dt2).getDays() + &quot; 天 &quot;);System.out.print(Hours.hoursBetween(dt1, dt2).getHours() % 24 + &quot; 小时 &quot;);System.out.print(Minutes.minutesBetween(dt1, dt2).getMinutes() % 60 + &quot; 分钟 &quot;);System.out.print(Seconds.secondsBetween(dt1, dt2).getSeconds() % 60+ &quot; 秒.&quot;); 格式化12String s = new DateTime().toString(DateTimeFormat.forPattern(&quot;yyyy-MM-dd&quot;));String s2 = new DateTime().toString(&quot;yyyy-MM-dd&quot;) 日期计算 plus/minus12345DateTime now = new DateTime();//当前时间DateTime tomorrowDt = now.plusDays(1);//明天int days = Days.daysBetween(now, tomorrowDt).getDays();System.out.println(days);//1 时间比较 isBefore/isAfter时间轴 12现在 isbefore 明天 trueboolean before = new DateTime().isBefore(new DateTime().plus(1)); ##官网http://www.joda.org/joda-time/userguide.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>joda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用记录]]></title>
    <url>%2F2017%2F11%2F%E5%B7%A5%E5%85%B7%2Fgit%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[流程12工作区 ---&gt; 暂存区 ----&gt; （历史）本地分支 ---&gt; 远程分支 add commit push 工作区和暂存区1234工作区：在电脑里能看到的目录版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。版本库里最重要的就是称为stage（或者叫index）的暂存区，(add操作)，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD，（commit操作）。 分支创建与切换123456git checkout -b dev #git checkout命令加上-b参数表示创建并切换相当于git branch dev #创建分支git checkout dev #切换分支git branch #查看分支 删除分支1git branch -d dev 合并分支fast-forward 快速合并不产生合并节点，看不出来曾经做过合并no-ff 合并生成合并节点 123git merge dev #git merge命令用于合并指定分支到当前分支git merge --no-ff -m &quot;merge with no-ff&quot; dev #合并生成合并节点 查看日志12git log #查看日志git log --graph --pretty=oneline --abbrev-commit #图形查看日志 查看具体某次提交1git show 3ad960849d6f10c92356ecdf952d5e4bfd0df1cd 版本回退和恢复12345678910111213回退工作区修改文件git checkout -- &lt;file&gt; 回退暂存区修改文件（add操作）git reset HEAD &lt;file&gt;git checkout -- &lt;file&gt; 回退本地分支修改文件 （add commit操作）git reset --hard HEAD^ #git reset HEAD~2恢复git reflog git reflog git reset --hard 0a1f420 暂时储藏修改当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场123git stash #储藏代码git stash list #查看列表git stash pop #回到工作现场 Reset、Checkout、Revert 的选择123456789reset 将一个分支的末端指向另一个提交。--soft – 缓存区和工作目录都不会被改变--mixed – 默认选项。缓存区和你指定的提交同步，但工作目录不受影响--hard – 缓存区和工作目录都同步到你指定的提交checkout 除了分支之外，你还可以传入提交的引用来 checkout 到任意的提交。git checkout HEAD~2Revert 撤销一个提交的同时会创建一个新的提交,相比 git reset，它不会改变现在的提交历史。因此，git revert 可以用在公共分支上，git reset 应该用在私有分支上。你也可以把 git revert 当作撤销已经提交的更改，而 git reset HEAD 用来撤销没有提交的更改。 git修改远程仓库地址方法有三种：查看远程地址git remote -v 修改命令 1git remote set-url origin [url] 先删后加 12git remote rm origingit remote add origin [url] 直接修改config文件 git上新建项目之后1234567891011…or create a new repository on the command line echo &quot;# hello&quot; &gt;&gt; README.md git init git add README.md git commit -m &quot;first commit&quot; git remote add origin git@github.com:hanqingsong/hello.git git push -u origin master …or push an existing repository from the command line git remote add origin git@github.com:hanqingsong/hello.git git push -u origin master 参考https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000https://github.com/geeeeeeeeek/git-recipes/wiki/5.2-%E4%BB%A3%E7%A0%81%E5%9B%9E%E6%BB%9A%EF%BC%9AReset%E3%80%81Checkout%E3%80%81Revert-%E7%9A%84%E9%80%89%E6%8B%A9https://github.com/geeeeeeeeek/git-recipes/wiki]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea常用快捷键mac版]]></title>
    <url>%2F2017%2F11%2F%E5%B7%A5%E5%85%B7%2Fidea%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AEmac%E7%89%88%2F</url>
    <content type="text"><![CDATA[编辑ctrl + j 快速查看文档⌘⇧↩ 自动结束代码，行末自动添加分号⌘⌥T 包围代码（使用if..else, try..catch, for, synchronized等包围选中的代码）alt+cmd+[ / ] 跳转到代码开头结尾处ctrl + O overide 方法ctrl + I 实现接口方法 alt+shift+u 驼峰和下划线转换 需要安装CamelCase 各种格式转换]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>idea</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令常用记录]]></title>
    <url>%2F2017%2F10%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%E5%B8%B8%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[创建多级文件夹 mkdir -p test1/test2/test3 修改权限包含子目录 chown -R 创建软连接 ln [参数][源文件或目录][目标文件或目录] ln -s xx.log xxf.log 递归拷贝这些及其子文件夹下的文件 cp -ri 查看文件夹下文件大小 du -h –max-depth=1 /mydata/ 清屏 clear 查看shell cat /etc/shells 查看使用的shell echo $SHELL 查看本地端口 netstat -ntlp]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令:Http请求get和post]]></title>
    <url>%2F2017%2F10%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9AHttp%E8%AF%B7%E6%B1%82get%E5%92%8Cpost%2F</url>
    <content type="text"><![CDATA[一、get请求： 1、使用curl命令： curl “http://www.baidu.com” 如果这里的URL指向的是一个文件或者一幅图都可以直接下载到本地 curl -i “http://www.baidu.com” 显示全部信息 curl -l “http://www.baidu.com” 只显示头部信息 curl -v “http://www.baidu.com” 显示get请求全过程解析 2、使用wget命令： wget “http://www.baidu.com”也可以 二、post请求 1、使用curl命令（通过-d参数，把访问参数放在里面）： curl -d “param1=value1¶m2=value2” “http://www.baidu.com” 2、使用wget命令：（–post-data参数来实现） wget –post-data ‘user=foo&amp;password=bar’ http://www.baidu.com 以上就是Linux模拟Http的get或post请求的方法了，这样一来Linux系统也能向远程服务器发送消息了。 示例：wget --post-data=&quot;&quot; http://mcs-inner.99bill.com/mcs-gateway/mcs/task/clear 三、curl (可直接发送格式化请求例如json)示例：目标url:http://fsc-inner.99bill.com/acs/deposit/{srcRef} 命令：curl -H &quot;Content-type: application/json&quot; -X POST -d &apos;{&quot;srcRef&quot;:&quot;1002&quot;}&apos;http://fsc-inner.99bill.com/acs/deposit/1002 参考http://blog.csdn.net/ai2000ai/article/details/56290142]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[升级jdk1.8报错：sun.security.validator.ValidatorException: Certificate signature algorithm disabled]]></title>
    <url>%2F2017%2F10%2F%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%2F%E5%8D%87%E7%BA%A7jdk1-8%E6%8A%A5%E9%94%99%EF%BC%9Asun-security-validator-ValidatorException-Certificate-signature%2F</url>
    <content type="text"><![CDATA[升级jdk1.8项目出错sun.security.validator.ValidatorException: Certificate signature algorithm disabled 报错原因是JDK8对SSL证书的算法安全要求提高，可以对比下7和8的区别12345678less /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home/jre/lib/security/java.security|grep disabledAlgorithms |grep -v &quot;#&quot;jdk.certpath.disabledAlgorithms=MD2, RSA keySize &lt; 1024jdk.tls.disabledAlgorithms=SSLv3less /Library/Java/JavaVirtualMachines/jdk1.8.0_*/Contents/Home/jre/lib/security/java.security|grep disabledAlgorithms |grep -v &quot;#&quot;jdk.certpath.disabledAlgorithms=MD2, MD5, SHA1 jdkCA &amp; usage TLSServer, \jdk.jar.disabledAlgorithms=MD2, MD5, RSA keySize &lt; 1024jdk.tls.disabledAlgorithms=SSLv3, RC4, MD5withRSA, DH keySize &lt; 768, \ 解决方法 简单做法是直接注释掉jdk.certpath.disabledAlgorithms 继承新的抽象类：X509ExtendedTrustManager123In the Java SE 7 release, the X509ExtendedTrustManager class is an abstract implementation of the X509TrustManager interface. It adds methods for connection-sensitive trust management. In addition, it enables endpoint verification at the TLS layer....Besides TLS 1.2 support, the X509ExtendedTrustManager class also support algorithm constraints and SSL layer hostname verification. 参考http://www.cnblogs.com/flyingeagle/articles/7508207.html]]></content>
      <categories>
        <category>问题记录</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[升级jdk1.8报错：sun.security.validator.ValidatorException: Certificate signature algorithm disabled]]></title>
    <url>%2F2017%2F10%2FJava%2F%E5%8D%87%E7%BA%A7jdk1-8%E6%8A%A5%E9%94%99%EF%BC%9Asun-security-validator-ValidatorException-Certificate-signature%2F</url>
    <content type="text"><![CDATA[升级jdk1.8项目出错sun.security.validator.ValidatorException: Certificate signature algorithm disabled 报错原因是JDK8对SSL证书的算法安全要求提高，可以对比下7和8的区别12345678less /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home/jre/lib/security/java.security|grep disabledAlgorithms |grep -v &quot;#&quot;jdk.certpath.disabledAlgorithms=MD2, RSA keySize &lt; 1024jdk.tls.disabledAlgorithms=SSLv3less /Library/Java/JavaVirtualMachines/jdk1.8.0_*/Contents/Home/jre/lib/security/java.security|grep disabledAlgorithms |grep -v &quot;#&quot;jdk.certpath.disabledAlgorithms=MD2, MD5, SHA1 jdkCA &amp; usage TLSServer, \jdk.jar.disabledAlgorithms=MD2, MD5, RSA keySize &lt; 1024jdk.tls.disabledAlgorithms=SSLv3, RC4, MD5withRSA, DH keySize &lt; 768, \ 解决方法 简单做法是直接注释掉jdk.certpath.disabledAlgorithms 继承新的抽象类：X509ExtendedTrustManager123In the Java SE 7 release, the X509ExtendedTrustManager class is an abstract implementation of the X509TrustManager interface. It adds methods for connection-sensitive trust management. In addition, it enables endpoint verification at the TLS layer....Besides TLS 1.2 support, the X509ExtendedTrustManager class also support algorithm constraints and SSL layer hostname verification. 参考http://www.cnblogs.com/flyingeagle/articles/7508207.html]]></content>
      <categories>
        <category>问题记录</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EFK-从零搭建日志系统]]></title>
    <url>%2F2017%2F10%2FELK%2FEFK-%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[分析日志需要包含字段： time level app_id instance_id日志从产生到消费，主要经历以下几个阶段：采集-&gt;传输-&gt;切分-&gt;检索。 区分实例 instance_id通过设置filebeat 系统搭建Filebeat 安装1234567891011121314curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.0.2-x86_64.rpmrpm -vi filebeat-5.0.2-x86_64.rpmvim /etc/filebeat/filebeat.yml修改 output.elasticsearch hosts 添加模板output.elasticsearch: hosts: [&quot;localhost:9200&quot;] template.name: &quot;filebeat&quot; template.path: &quot;filebeat.template.json&quot; template.overwrite: false启动/etc/init.d/filebeat startservice filebeat start elasticsearch 安装12345678910wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.3.rpmsha1sum elasticsearch-5.6.3.rpm sudo rpm --install elasticsearch-5.6.3.rpm### NOT starting on installation, please execute the following statements to configure elasticsearch service to start automatically using chkconfig sudo chkconfig --add elasticsearch### You can start elasticsearch service by executing sudo service elasticsearch startservice elasticsearch start 启动异常：Starting elasticsearch: Elasticsearch requires at least Java 8 but your Java version from /usr/bin/java does not meet this requirement 原因是java8安装，java版本管理工具没有更改1234567ll /usr/bin/java/usr/bin/java -&gt; /etc/alternatives/javaupdate-alternatives --config javaupdate-alternatives --install /usr/bin/java java /usr/local/java/jdk/jdk1.8.0_112/bin/java 300update-alternatives --install /usr/bin/javac javac /usr/local/java/jdk/jdk1.8.0_112/bin/javac 300 验证是否成功 curl http://localhost:9200/ 安装Kibana12345678wget https://artifacts.elastic.co/downloads/kibana/kibana-5.6.3-i686.rpmsha1sum kibana-5.6.3-i686.rpm sudo rpm --install kibana-5.6.3-i686.rpmservice kibana startservice kibana stop访问 http://localhost:5601 修改日志收集路径vim /etc/elasticsearch/elasticsearch.yml设置path.data: /mydata/elk/elasticsearch/datapath.logs: /mydata/elk/elasticsearch/logs如果重启会报错detected index data in default.path.data [/var/lib/elasticsearch/nodes/0/indices] where there should not be any需要把/var/lib/elasticsearch/下的文件夹移动到/mydata/elk/elasticsearch/下，删除/var/lib/elasticsearch/ kibana使用Lucene query syntax 简单的文本搜索，直接输入文本字符串。比如，如果你在搜索网站服务器日志，你可以输入 safari 来搜索各字段中的 safari 单词。 要搜索特定字段中的值，则在值前加上字段名。比如，你可以输入 status:200 来限制搜索结果都是在 status 字段里有 200 内容。 要搜索一个值的范围，你可以用范围查询语法，[START_VALUE TO END_VALUE]。比如，要查找 4xx 的状态码，你可以输入 status:[400 TO 499]。 要指定更复杂的搜索标准，你可以用布尔操作符 AND, OR, 和 NOT。比如，要查找 4xx 的状态码，还是 php 或 html 结尾的数据，你可以输入 status:[400 TO 499] AND (extension:php OR extension:html)。 检查健康状况curl localhost:9200/_cat/health 查看索引curl -XGET ‘http://localhost:9200/_cat/indices?v‘ 删除索引curl -XDELETE ‘http://10.1.1.92:9200/filebeat-2017.10.*‘ 参考https://mp.weixin.qq.com/s/onrBwQ0vyLJYWD_FRnNjEgELKstack 中文指南：https://kibana.logstash.es/content/kibana/v5/discover.html]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>日志系统</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令：统计命令]]></title>
    <url>%2F2017%2F10%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9A%E7%BB%9F%E8%AE%A1%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一些实用的Linux文本操作命令，包括wc(统计)、cut(切分)、sort(排序)、uniq(去重)、grep(查找)、sed(替换、插入、删除)、awk(文本分析)。 wc(统计)12345# wc [-lwm]选项与参数：-l ：仅列出行；-w ：仅列出多少字(英文单字)；-m ：多少字符； cut(切分)1234567891011cut [-bn] [file] 或 cut [-c] [file] 或 cut [-df] [file] 使用说明 cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。 如果不指定 File 参数，cut 命令将读取标准输入。必须指定 -b、-c 或 -f 标志之一。 主要参数 -b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域。 -n ：取消分割多字节字符。仅和 -b 标志一起使用。如果字符的最后一个字节落在由 -b 标志的 List 参数指示的&lt;br /&gt;范围之内，该字符将被写出；否则，该字符将被排除。 sort(排序)123456789101112131415 sort命令是帮我们依据不同的数据类型进行排序，其语法及常用参数格式：sort [-bcfMnrtk][源文件][-o 输出文件] 补充说明：sort可针对文本文件的内容，以行为单位来排序。 参数： -b 忽略每行前面开始出的空格字符。 -c 检查文件是否已经按照顺序排序。 -f 排序时，忽略大小写字母。 -M 将前面3个字母依照月份的缩写进行排序。 -n 依照数值的大小排序。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k 选择以哪个区间进行排序。 uniq(去重)uniq命令可以去除排序过的文件中的重复行，因此uniq经常和sort合用。也就是说，为了使uniq起作用，所有的重复行必须是相邻的。12345# uniq [-icu]选项与参数：-i ：忽略大小写字符的不同；-c ：进行计数-u ：只显示唯一的行 grep(查找)1234567891011121314151617181920212223Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。grep [options] 主要参数 [options]主要参数： －c：只输出匹配行的计数。 －I：不区分大 小写(只适用于单字符)。 －h：查询多文件时不显示文件名。 －l：查询多文件时只输出包含匹配字符的文件名。 －n：显示匹配行及 行号。 －s：不显示不存在或无匹配文本的错误信息。 －v：显示不包含匹配文本的所有行。 -E：使用正则 pattern正则表达式主要参数： \： 忽略正则表达式中特殊字符的原有含义。 ^：匹配正则表达式的开始行。 $: 匹配正则表达式的结束行。 \&lt;：从匹配正则表达 式的行开始。 \&gt;：到匹配正则表达式的行结束。 [ ]：单个字符，如[A]即A符合要求 。 [ - ]：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。 。：所有的单个字符。 * ：有字符，长度可以为0。 sed(替换、插入、删除)sed是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作，下面先了解一下sed的用法。sed命令行格式为：123456789101112131415sed [-nefri] ‘command’ 输入文本 常用选项： -n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 -e∶直接在指令列模式上进行 sed 的动作编辑； -f∶直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作； -r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法) -i∶直接修改读取的档案内容，而不是由萤幕输出。 常用命令： a ∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ∶删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～ s ∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ sed 提取匹配的字符串内容123# STR=&quot;MAIL FROM(CCC) TO(DDD)&quot;# echo $STR | sed &apos;s/^.*FROM(\(.*\)).*TO(\(.*\)).*$/\1-\2/g&apos;CCC-DDD s表示替换，组匹配信息(.*),第一个为\1,第二个\2以此类推 12345&quot;09/Jan/2018:00:02:58 +0800&quot;,&quot;210.22.172.146&quot;,&quot;-&quot;,&quot;-&quot;,&quot;-&quot;,&quot;api.fastschool.cn&quot;,&quot;ded92c009aaa4582a6cf9b644fa62aa6&quot;,&quot;GET /clog/a.gif?action=FS_UploadLog&amp;clientIp=%28null%29&amp;clientVersion=3.8.7&amp;debugInfo=20180108__NumOfLine_117_&amp;logType=debug&amp;logVersion=1.0&amp;netType=wifi&amp;osName=iPad&amp;osVersion=10.3&amp;platform=iOS&amp;tag=FSUploadLog&amp;ts=2018-01-09%2000%3A02%3A56.784&amp;userLid=a91e0cffbe474635b8ec4861a58b1a97&amp;userToken=ded92c009aaa4582a6cf9b644fa62aa6&amp;wifiName=TP-LINK_BF2AF0 HTTP/1.1&quot;,&quot;-&quot;,&quot;-&quot;,&quot;prod:stu_cli, channel:AppStore, os:iOS, osVer:10.3.3, mobile:iPad, vName:3.8.7, env:RE&quot;,&quot;200&quot;,&quot;0.000&quot;,&quot;0&quot;,&quot;-&quot;,&quot;-&quot;,&quot;*/*&quot;,&quot;nginx-111&quot;,&quot;-&quot;# less loginfo.txt |awk -F&apos;&quot;,&quot;&apos; &apos;&#123;print $8&#125;&apos; |sed &apos;s/^.*\(action=[a-zA-Z_]*\).*\(platform=[a-zA-Z_]*\).*$/\1 \2/g&apos;action=FS_StartUploadLog_ToCOS platform=iOS awk(文本分析)awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理1awk &apos;&#123;pattern + action&#125;&apos; &#123;filenames&#125; 尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。 awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。 通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。 参考博客出处：http://www.cnblogs.com/maybe2030/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iterm2使用技巧]]></title>
    <url>%2F2017%2F10%2F%E5%B7%A5%E5%85%B7%2Fiterm2%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[使用快捷键12345678910⌘ + 数字: 切换标签页。 ⌘ + 方向键 按方向切换标签页。⌘ + enter: 切换全屏⌘ + f: 查找。支持正则。其中查找的内容会被自动复制。鼠标去选中的内容也会自动复制⌘ + d: 垂直分屏，⌘ + shift + d: 水平分屏。使用⌘ + ]和⌘ + [在最近使用的分屏直接切换.⌘ + t :新的标签页⌘ + w :关闭当前标签页⌘ + ；:自动补全历史命令⌘ + —/+/0: 调整字体大小⌘ + /: 找到当前光标位置 命令行123456789101112ctrl + u: 清空当前行。ctrl + a: 到行首ctrl + e: 行末ctrl + f/b: 前进后退，相当于左右方向键ctrl + p: 上一条命令，相当于方向键上ctrl + r: 搜索命令历史ctrl + d: 删除当前字符ctrl + h: 删除之前的字符ctrl + w: 删除光标前的单词ctrl + k: 删除到文本末尾ctrl + t: 交换光标处文本⌘ + r:清屏，其实是滚到新的一屏，并没有清空。ctrl + l 也可以做到。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>iterm2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx添加日志分割logrotate]]></title>
    <url>%2F2017%2F10%2FNginx%2Fnginx%E6%B7%BB%E5%8A%A0%E6%97%A5%E5%BF%97%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[logrotate简介logrotate 是Linux系统日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，我们把它叫做“转储”。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行。logrotate 程序还可以用于压缩日志文件，以及发送日志到指定的E-mail。默认的logrotate被加入cron的/etc/cron.daily中作为每日任务执行。/etc/logrotate.d/* 为/etc/logrotate.conf默认包含目录其中文件也会被logrotate读取。指明每个日志文件的特定规则。/var/lib/logrotate/status中默认记录logrotate上次轮换日志文件的时间。 logrotate安装centos是默认有安装yum install logrotate安装完成之后在，在/etc/logrotate.d/有以下脚本12345678$ ll /etc/logrotate.d/total 24drwxr-xr-x. 2 root root 4096 Mar 3 2016 2016-03-03-rw-r--r--. 1 root root 103 Jul 14 2015 dracut-rw-r--r-- 1 root root 217 Oct 31 2016 nginx-rw-r--r--. 1 root root 329 Jul 17 2012 psacct-rw-r--r--. 1 root root 265 Mar 3 2016 syslog-rw-r--r--. 1 root root 100 Feb 22 2013 yum 运行机制crontab会每天定时执行/etc/cron.daily目录下的脚本，在这个目录有个logrotate脚本，脚本内容为12345678#!/bin/sh/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1EXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;fiexit 0 每天执行一次/usr/sbin/logrotate /etc/logrotate.conf，logrotate.conf中include /etc/logrotate.d nginx脚本1234567891011/var/log/nginx/*log &#123; daily rotate 10 missingok notifempty compress sharedscripts postrotate /bin/kill -USR1 $(cat /var/run/nginx.pid 2&gt;/dev/null) 2&gt;/dev/null || : endscript&#125; 1234567891011121314151617181920212223compress 通过gzip压缩转储以后的日志nocompress 不压缩copytruncate 用于还在打开中的日志文件，把当前日志备份并截断nocopytruncate 备份日志文件但是不截断create mode owner group 转储文件，使用指定的文件模式创建新的日志文件nocreate 不建立新的日志文件delaycompress 和 compress 一起使用时，转储的日志文件到下一次转储时才压缩nodelaycompress 覆盖 delaycompress 选项，转储同时压缩。errors address 专储时的错误信息发送到指定的Email 地址ifempty 即使是空文件也转储，这个是 logrotate 的缺省选项。notifempty 如果是空文件的话，不转储mail address 把转储的日志文件发送到指定的E-mail 地址nomail 转储时不发送日志文件olddir directory 转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统noolddir 转储后的日志文件和当前日志文件放在同一个目录下prerotate/endscript 在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行postrotate/endscript 在转储以后需要执行的命令可以放入这个对，这两个关键字必须单独成行daily 指定转储周期为每天weekly 指定转储周期为每周monthly 指定转储周期为每月rotate count 指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份tabootext [+] list 让logrotate 不转储指定扩展名的文件，缺省的扩展名是：.rpm-orig, .rpmsave, v, 和 ~ size size 当日志文件到达指定的大小时才转储，bytes(缺省)及KB(sizek)或MB(sizem) 命令立刻执行分割：/usr/sbin/logrotate -vf /etc/logrotate.d/nginx查看执行状态 cat /var/lib/logrotate.status 添加定时任务1234crontab -e #添加以下代码， #每天凌晨定时执行脚本# crond-id-02:nginx_logs logroate0 0 * * * /usr/sbin/logrotate -vf /etc/logrotate.d/nginx &gt;/dev/null 2&gt;&amp;1]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令：统计分析日志]]></title>
    <url>%2F2017%2F10%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9A%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[liunx服务器上生成的日志文件进行分析，文件格式如下：id time1001,2011-08-19 00:00:001002,2011-08-19 01:00:001001,2011-08-19 02:00:001003,2011-08-19 03:00:00 linux命令如下：排重后id个数 cat ****.txt | awk &apos;{print $1}&apos; | sort | uniq -c | wc -l 按id出现次数排序 cat ****.txt | awk &apos;{print $1}&apos; | sort | uniq -c | sort -k 1 -n -r | wc -l 将结果导入文件 cat ****.txt | awk &apos;{print $1}&apos; | sort | uniq -c | sort -k 1 -n -r | wc -l &gt; result.txt 命令解析：sort：表示前面输入的结果文件中的内容进行排序。sort命令是对于每一行的内容根据字典序（ASCII码）进行排序，这样可以保证重复的记录时相邻的。 awk ‘{print $1}’ ：日志记录中的第一个字段。 uniq –c：表示合并相邻的重复记录，并统计重复数。因为uniq -c 只会合并相邻的记录，所以在使用该命令之前需要先排序。 sort –k 1 -n -r|wc –l：经过uniq -c 处理之后的数据格式形如”2 data”，第一个字段是数字，表示重复的记录数；第二个字段为记录的内容。我们将对此内容进行排序。sort -k 1表示对于每行的第一个字段进行排序，这里即指代表重复记录数的那个字段。因为sort命令的默认排序是按照ASCII，这就会导致按从大到小进行排序时，数值2会排在数值11的前面，所以需要使用-n 参数指定sort命令按照数值大小进行排序。-r 表示逆序，即按照从大到小的顺序进行排序。 wc命令 wc命令的功能为统计指定文件中的字节数、字数、行数, 并将统计结果显示输出。 语法：wc [选项] 文件… 说明：该命令统计给定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所有指定文件的总统计数。字是由空格字符区分开的最大字符串。 该命令各选项含义如下： - c 统计字节数。 - l 统计行数。 - w 统计字数 参考http://wuzhangshu927.blog.163.com/blog/static/114224687201171941937445/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令：压缩命令]]></title>
    <url>%2F2017%2F10%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9A%E5%8E%8B%E7%BC%A9%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[tar命令 解包：tar zxvf FileName.tar 解包到指定文件夹：tar zxvf FileName.tar -C dirname 打包：tar czvf FileName.tar DirName gz命令 解压：gunzip FileName.gz 解压：gzip -d FileName.gz 压缩：gzip FileName tar.gz 解压：tar zxvf FileName.tar.gz 压缩：tar zcvf FileName.tar.gz DirName 压缩多个文件：tar zcvf FileName.tar.gz DirName1 DirName2 DirName3 zip命令 解压：unzip FileName.zip 解压到指定目录：unzip -d /home/sunny myfile.zip 压缩：zip -r FileName.zip DirName]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令: 运行远程命令]]></title>
    <url>%2F2017%2F10%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9A%E8%BF%90%E8%A1%8C%E8%BF%9C%E7%A8%8B%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[运行远程命令123➜ ~ ssh root@dev &quot;ls /mydata&quot;appsdevelop]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令：查看文件夹下文件大小]]></title>
    <url>%2F2017%2F10%2FLinux%2FLinux%E5%91%BD%E4%BB%A4%EF%BC%9A%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%2F</url>
    <content type="text"><![CDATA[查看文件夹下文件大小du [-abcDhHklmsSx] [-L &lt;符号连接&gt;][-X &lt;文件&gt;][–block-size][–exclude=&lt;目录或文件&gt;] [–max-depth=&lt;目录层数&gt;][–help][–version][目录或文件] 1du -h --max-depth=1 /mydata/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-part5:Stacks]]></title>
    <url>%2F2017%2F10%2FDocker%2Fdocker-part5-Stacks%2F</url>
    <content type="text"><![CDATA[新增一个服务（service）visualizer修改docker-compose.yml123456789101112131415161718192021222324252627282930version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: &quot;0.1&quot; memory: 50M ports: - &quot;80:80&quot; networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 更新服务123456789➜ docker-test docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_webCreating service getstartedlab_visualizer➜ docker-test docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.09.0-cemyvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.09.0-ce 访问 http://192.168.99.100:8080/ 持久化redis数据服务修改docker-compose.yml123456789101112131415161718192021222324252627282930313233343536373839404142version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: 842071912/start-docker1:hellopy deploy: replicas: 5 resources: limits: cpus: &quot;0.1&quot; memory: 50M restart_policy: condition: on-failure ports: - &quot;80:80&quot; networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - &quot;8080:8080&quot; volumes: - &quot;/var/run/docker.sock:/var/run/docker.sock&quot; deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - &quot;6379:6379&quot; volumes: - /home/docker/data:/data deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnetnetworks: webnet: 创建./data文件夹123456789101112➜ docker-test docker-machine ssh myvm1 &quot;mkdir ./data&quot;➜ docker-test docker stack deploy -c docker-compose.yml getstartedlabUpdating service getstartedlab_web (id: p3yof4klife0ulvn7fqwjrhkm)Updating service getstartedlab_visualizer (id: s550x4sifn20ab391fsywu0l2)Updating service getstartedlab_redis (id: a2eh1a3c3di608fsa00l7uvj8)➜ docker-test docker service lsID NAME MODE REPLICAS IMAGE PORTSa2eh1a3c3di6 getstartedlab_redis replicated 1/1 redis:latest *:6379-&gt;6379/tcps550x4sifn20 getstartedlab_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080-&gt;8080/tcpp3yof4klife0 getstartedlab_web replicated 5/5 842071912/start-docker1:hellopy *:80-&gt;80/tcp 访问 http://192.168.99.100:8080/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-part4:swarms]]></title>
    <url>%2F2017%2F10%2FDocker%2Fdocker-part4-swarms%2F</url>
    <content type="text"><![CDATA[设置swarmmac系统下需要安装 install Oracle VirtualBox 创建集群使用docker-machine创建VMs,创建有可能会失败多执行几次123456789101112131415161718192021222324252627282930313233➜ docker-test docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS➜ docker-test docker-machine create --driver virtualbox myvm1Running pre-create checks...(myvm1) No default Boot2Docker ISO found locally, downloading the latest release...(myvm1) Latest release for github.com/boot2docker/boot2docker is v17.09.0-ce(myvm1) Downloading /Users/hanqingsong/.docker/machine/cache/boot2docker.iso from https://github.com/boot2docker/boot2docker/releases/download/v17.09.0-ce/boot2docker.iso...(myvm1) 0%....10%....20%....30%....40%....50%....60%....70%....80%....90%....100%Creating machine...(myvm1) Copying /Users/hanqingsong/.docker/machine/cache/boot2docker.iso to /Users/hanqingsong/.docker/machine/machines/myvm1/boot2docker.iso...(myvm1) Creating VirtualBox VM...(myvm1) Creating SSH key...(myvm1) Starting the VM...(myvm1) Check network to re-create if needed...(myvm1) Found a new host-only adapter: &quot;vboxnet0&quot;(myvm1) Waiting for an IP...Waiting for machine to be running, this may take a few minutes...Detecting operating system of created instance...Waiting for SSH to be available...Detecting the provisioner...Provisioning with boot2docker...Copying certs to the local machine directory...Copying certs to the remote machine...Setting Docker configuration on the remote daemon...Checking connection to Docker...Docker is up and running!To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env myvm1➜ docker-test docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 - virtualbox Running tcp://192.168.99.100:2376 v17.09.0-cemyvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.09.0-ce 初始化swarm添加节点设置myvm1为swarm管理者12345678➜ docker-test docker-machine ssh myvm1 &quot;docker swarm init --advertise-addr 192.168.99.100&quot; Swarm initialized: current node (mwshg3zvljp17muqpuua5l3d1) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-26jjkt2i3rul2qp7hwdp2m3ek1vegmumr6mk07ba8orc886ix2-c41i1zkhtnjqartdv6l75ms8h 192.168.99.100:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions. myvm2添加为worker12➜ docker-test docker-machine ssh myvm2 &quot;docker swarm join --token SWMTKN-1-26jjkt2i3rul2qp7hwdp2m3ek1vegmumr6mk07ba8orc886ix2-c41i1zkhtnjqartdv6l75ms8h 192.168.99.100:2377&quot;This node joined a swarm as a worker. 查看swarm节点1234➜ docker-test docker-machine ssh myvm1 &quot;docker node ls&quot;ID HOSTNAME STATUS AVAILABILITY MANAGER STATUSmwshg3zvljp17muqpuua5l3d1 * myvm1 Ready Active Leaderurdtegb3yanqi0d98vzm49tof myvm2 Ready Active 在swarm集群部署应用设置myvm1为激活状态1234567891011121314➜ docker-test docker-machine env myvm1export DOCKER_TLS_VERIFY=&quot;1&quot;export DOCKER_HOST=&quot;tcp://192.168.99.100:2376&quot;export DOCKER_CERT_PATH=&quot;/Users/hanqingsong/.docker/machine/machines/myvm1&quot;export DOCKER_MACHINE_NAME=&quot;myvm1&quot;# Run this command to configure your shell:# eval $(docker-machine env myvm1)➜ docker-test eval $(docker-machine env myvm1)➜ docker-test docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 * virtualbox Running tcp://192.168.99.100:2376 v17.09.0-cemyvm2 - virtualbox Running tcp://192.168.99.101:2376 v17.09.0-ce 在swarm manager部署应用123➜ docker-test docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web 查看服务部署信息1234567➜ docker-test docker stack ps getstartedlabID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSqvs0h0pqgsou getstartedlab_web.1 842071912/start-docker1:hellopy myvm1 Running Preparing about a minute agojtlfqsejqnmo getstartedlab_web.2 842071912/start-docker1:hellopy myvm2 Running Running 24 seconds agowauh0t4cybvn getstartedlab_web.3 842071912/start-docker1:hellopy myvm1 Running Preparing about a minute agofeyi52iwjpa2 getstartedlab_web.4 842071912/start-docker1:hellopy myvm2 Running Running 24 seconds agom7mz2kevh15r getstartedlab_web.5 842071912/start-docker1:hellopy myvm2 Running Running 24 seconds ago 清除和重启 tear down the stack 123 ➜ docker-test docker stack rm getstartedlabRemoving service getstartedlab_webRemoving network getstartedlab_webnet Keep the swarm or remove it?At some point later, you can remove this swarm if you want to with docker-machine ssh myvm2 “docker swarm leave” on the worker and docker-machine ssh myvm1 “docker swarm leave –force” on the manager, but you’ll need this swarm for part 5, so please keep it around for now. 123456789101112➜ docker-test eval $(docker-machine env -u)➜ docker-test docker-machine stop $(docker-machine ls -q)Stopping &quot;myvm2&quot;...Stopping &quot;myvm1&quot;...Machine &quot;myvm2&quot; was stopped.Machine &quot;myvm1&quot; was stopped.➜ docker-test docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSmyvm1 - virtualbox Stopped Unknownmyvm2 - virtualbox Stopped Unknown 命令1234567891011121314docker-machine create --driver virtualbox myvm1 # Create a VM (Mac, Win7, Linux)docker-machine create -d hyperv --hyperv-virtual-switch &quot;myswitch&quot; myvm1 # Win10docker-machine env myvm1 # View basic information about your nodedocker-machine ssh myvm1 &quot;docker node ls&quot; # List the nodes in your swarmdocker-machine ssh myvm1 &quot;docker node inspect &lt;node ID&gt;&quot; # Inspect a nodedocker-machine ssh myvm1 &quot;docker swarm join-token -q worker&quot; # View join tokendocker-machine ssh myvm1 # Open an SSH session with the VM; type &quot;exit&quot; to enddocker-machine ssh myvm2 &quot;docker swarm leave&quot; # Make the worker leave the swarmdocker-machine ssh myvm1 &quot;docker swarm leave -f&quot; # Make master leave, kill swarmdocker-machine start myvm1 # Start a VM that is currently not runningdocker-machine stop $(docker-machine ls -q) # Stop all running VMsdocker-machine rm $(docker-machine ls -q) # Delete all VMs and their disk imagesdocker-machine scp docker-compose.yml myvm1:~ # Copy file to node&apos;s home dirdocker-machine ssh myvm1 &quot;docker stack deploy -c &lt;file&gt; &lt;app&gt;&quot; # Deploy an app]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-part3:services]]></title>
    <url>%2F2017%2F10%2FDocker%2Fdocker-part3-services%2F</url>
    <content type="text"><![CDATA[docker-compose.ymldocker-compose.yml定义了容器的行为。 12345678910111213141516171819version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: &quot;0.1&quot; memory: 50M restart_policy: condition: on-failure ports: - &quot;80:80&quot; networks: - webnetnetworks: webnet: 运行负载均衡应用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748➜ docker-test docker swarm initSwarm initialized: current node (scxmr99cp0d6zjpajrckdktmk) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-19wb8qe3cws960d8famp2lix8t1d6wza4eg9fw7geklefqjrvh-82wzkvoszligqto4eoe2ufail 192.168.65.2:2377To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions.➜ docker-test docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web➜ docker-test docker service lsID NAME MODE REPLICAS IMAGE PORTSlrd7bsarm31c getstartedlab_web replicated 5/5 842071912/start-docker1:hellopy *:80-&gt;80/tcp➜ docker-test docker stack lsNAME SERVICESgetstartedlab 1➜ docker-test docker service ps lrd7bsarm31cID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSpv0xalnz0jub getstartedlab_web.1 842071912/start-docker1:hellopy moby Running Running 2 minutes agoqrkj0dctgukn getstartedlab_web.2 842071912/start-docker1:hellopy moby Running Running 2 minutes agoxq97vphe37h5 getstartedlab_web.3 842071912/start-docker1:hellopy moby Running Running 2 minutes agokc0kj4tdzlpz getstartedlab_web.4 842071912/start-docker1:hellopy moby Running Running 2 minutes ago5roeqr1o8le3 getstartedlab_web.5 842071912/start-docker1:hellopy moby Running Running 2 minutes ago➜ docker-test docker container ls -q3b010bc1ba11e9c89868d2ee34cc4a84736ab697e352c20592db487d0025➜ docker-test docker stack rm getstartedlabRemoving service getstartedlab_webRemoving network getstartedlab_webnet➜ docker-test docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUSscxmr99cp0d6zjpajrckdktmk * moby Ready Active Leader➜ docker-test docker swarm leave --forceNode left the swarm.➜ docker-test docker node lsError response from daemon: This node is not a swarm manager. Use &quot;docker swarm init&quot; or &quot;docker swarm join&quot; to connect this node to swarm and try again. 命令集12345678docker swarm initdocker stack ls # List stacks or appsdocker stack deploy -c &lt;composefile&gt; &lt;appname&gt; # Run the specified Compose filedocker service ls # List running services associated with an appdocker service ps &lt;service&gt; # List tasks associated with an appdocker inspect &lt;task or container&gt; # Inspect task or containerdocker container ls -q # List container IDsdocker stack rm &lt;appname&gt; # Tear down an application]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制数组转十六进制]]></title>
    <url>%2F2017%2F10%2FJava%2F%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E7%BB%84%E8%BD%AC%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6%2F</url>
    <content type="text"><![CDATA[二进制数组转十六进制1234567891011121314private static String byte2hex(byte [] buffer)&#123; String h = &quot;&quot;; for(int i = 0; i &lt; buffer.length; i++)&#123; String temp = Integer.toHexString(buffer[i] &amp; 0xFF); if(temp.length() == 1)&#123; temp = &quot;0&quot; + temp; &#125; h = h + &quot; &quot;+ temp; &#125; return h;&#125; 二进制输出二进制字符串1234567891011private static String byte2Str(byte [] buffer)&#123; String h = &quot;&quot;; for(int i = 0; i &lt; buffer.length; i++)&#123; String temp = Integer.toBinaryString(buffer[i]); h = h + &quot; &quot;+ temp; &#125; return h;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>byte</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea免费激活方法]]></title>
    <url>%2F2017%2F10%2F%E5%B7%A5%E5%85%B7%2Fidea%E5%85%8D%E8%B4%B9%E6%BF%80%E6%B4%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[获取注册码http://idea.lanyus.com/http://www.98key.com/idea 填入license serverhttp://intellij.mandroid.cn/http://idea.imsxm.com/http://idea.iteblog.com/key.php]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac 安装使用Docker]]></title>
    <url>%2F2017%2F10%2Fmac%2Fmac-%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8Docker%2F</url>
    <content type="text"><![CDATA[docker安装与启动docker官网地址,下载dmg安装。12345678910111213$ docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.$ docker --version 构建第一个app官网文档 Build app 1234567891011121314$ lsDockerfile app.py requirements.txt$ docker build -t friendlyhello .Sending build context to Docker daemon 4.608kBStep 1/7 : FROM python:2.7-slim2.7-slim: Pulling from library/python$ docker imagesREPOSITORY TAG IMAGE IDfriendlyhello latest 326387cea398$ docker run -p 4000:80 friendlyhello 或 docker run -d -p 4000:80 friendlyhello #-d 后台运行 访问http://localhost:4000。CTRL+C退出 后台运行退出时12$ docker container ls #获取短CONTAINER ID$ docker stop id 分享image123456789docker logindocker tag image username/repository:tag #Tag the image比如：docker tag friendlyhello john/get-started:part2docker imagesdocker push username/repository:tag #Publish the imagedocker run -p 4000:80 username/repository:tag #Pull and run the image from the remote repository 容器&amp;镜像命令列表12345678910111213141516docker build -t friendlyname . # Create image using this directory&apos;s Dockerfiledocker run -p 4000:80 friendlyname # Run &quot;friendlyname&quot; mapping port 4000 to 80docker run -d -p 4000:80 friendlyname # Same thing, but in detached modedocker container ls # List all running containersdocker container ls -a # List all containers, even those not runningdocker container stop &lt;hash&gt; # Gracefully stop the specified containerdocker container kill &lt;hash&gt; # Force shutdown of the specified containerdocker container rm &lt;hash&gt; # Remove specified container from this machinedocker container rm $(docker container ls -a -q) # Remove all containersdocker image ls -a # List all images on this machinedocker image rm &lt;image id&gt; # Remove specified image from this machinedocker image rm $(docker image ls -a -q) # Remove all images from this machinedocker login # Log in this CLI session using your Docker credentialsdocker tag &lt;image&gt; username/repository:tag # Tag &lt;image&gt; for upload to registrydocker push username/repository:tag # Upload tagged image to registrydocker run username/repository:tag # Run image from a registry 镜像的获取12345678# 搜索镜像docker search &lt;image&gt; # 在docker index中搜索image# 下载镜像docker pull &lt;image&gt; # 从docker registry server 中下拉image# 查看镜像 docker images： # 列出imagesdocker images -a # 列出所有的images（包含历史）docker rmi &lt;image ID&gt;： # 删除一个或多个image 容器的使用12345678910111213141516# 查看容器 docker ps ：列出当前所有正在运行的container docker ps -l ：列出最近一次启动的container docker ps -a ：列出所有的container（包含历史，即运行过的container） docker ps -q ：列出最近一次运行的container ID# 再次启动容器 docker start/stop/restart &lt;container&gt; #：开启/停止/重启container docker start [container_id] #：再次运行某个container （包括历史container）#进入正在运行的docker容器 docker exec -it [container_id] /bin/bash docker run -i -t -p &lt;host_port:contain_port&gt; #：映射 HOST 端口到容器，方便外部访问容器内服务，host_port 可以省略，省略表示把 container_port 映射到一个动态端口。# 删除容器 docker rm &lt;container...&gt; #：删除一个或多个container docker rm `docker ps -a -q` #：删除所有的container docker ps -a -q | xargs docker rm #：同上, 删除所有的container]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm 工具]]></title>
    <url>%2F2017%2F10%2FJVM%2Fjvm-%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[常用工具jps：主要用来输出JVM中运行的进程状态信息 (Java Virtual Machine Process Status Tool)、jstack：主要用来查看某个Java进程内的线程堆栈信息jmap：生成堆快照jstat: 显示进程中的类装载、内存、垃圾收集、JIT编译等运行数据jhat：html形式显示对象占用内存大小以及引用情况jconsole（图形工具）jvisualvm（图形工具）MAT （第三方图形工具） jpsjps主要用来输出JVM中运行的进程状态信息。语法格式如下： jps [options] [hostid]-q 不输出类名、Jar名和传入main方法的参数-m 输出传入main方法的参数-l 输出main类或Jar的全限名-v 输出传入JVM的参数 jstackjstack主要用来查看某个Java进程内的线程堆栈信息。语法格式如下： jstack [option] pidjstack [option] executable corejstack [option] [server-id@]remote-hostname-or-ip-l long listings，会打印出额外的锁信息，在发生死锁时可以用jstack -l pid来观察锁持有情况-m mixed mode，不仅会输出Java堆栈信息，还会输出C/C++堆栈信息（比如Native方法） jmap jmap -heap :当前堆内存分布信息，如From space, To Space等占用内存大小jmap -histo : 当前堆中对象占用内存大小情况，柱状图数据结构组织。可以简单得定位下当前占用内存最大的几个对象jmap -histo:live:先触发一次gc , 再统计对象占用内存情况。可以简单得定位下当前占用内存最大的几个对象以及对象是否可以被gc回收jmap -dump:format=b,file=heapDump: 导出堆详细使用信息，b表示二进制文件，之后采用其他工具分析，如jhat,mat.非常详细，可分析到对象之间的引用关系等。 jstat显示进程中的类装载、内存、垃圾收集、JIT编译等运行数据目前感觉用上的都是gc记录查看，实际还没太用过 jstat -gc 3331 250 20: 查询进程2764的垃圾收集情况，每250毫秒查询一次，一共查询20次。jstat -gcause S0C : survivor0区的总容量S1C : survivor1区的总容量S0U : survivor0区已使用的容量S1U : survivor1区已使用的容量EC : Eden区的总容量EU : Eden区已使用的容量OC : Old区的总容量OU : Old区已使用的容量PC 当前perm的容量 (KB)PU perm的使用 (KB)YGC : 新生代垃圾回收次数YGCT : 新生代垃圾回收时间FGC : 老年代垃圾回收次数FGCT : 老年代垃圾回收时间GCT : 垃圾回收总消耗时间 jhat可用来分析 jmap dump生成的堆信息二进制文件。html形式显示对象占用内存大小以及引用情况，但显示得并不友好。感觉比较鸡肋。 jhat file jconsole（图形工具）Jconsole（Java Monitoring and Management Console）从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控 jvisualvm（图形工具）用于查看 Java 虚拟机 (Java Virtual Machine, JVM) 上运行的基于 Java 技术的应用程序（Java 应用程序）的详细信息。 MATMAT(Memory Analyzer Tool)，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗。 资料https://my.oschina.net/feichexia/blog/196575http://www.jianshu.com/p/6bbab921102bhttp://www.ityouknow.com/]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea初始化设置]]></title>
    <url>%2F2017%2F09%2F%E5%B7%A5%E5%85%B7%2Fidea%E5%88%9D%E5%A7%8B%E5%8C%96%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[编程字体设置根据个人喜好选择喜欢的编程字体editor–&gt;font–&gt;font选用 Monospace 14字体，行距1.1（个人喜欢）或选用 Courier new 15字体，行距1. 去除大小写敏感 Editor –&gt; Code Completion，设置Case sensitive completion为none。 显示行号Editor -&gt; General -&gt; Appearance，勾选show line numbers。 设置编辑器和控制台的字体Appearence–&gt;override default fonts by设置为consolasCourier 修改文件默认签名Editor-&gt;File and Code Templates-&gt;Includes-&gt;File Header 123/** * Created by $&#123;USER&#125; on $&#123;DATE&#125;. */ 添加自定义代码补全Live TemplatesEditor -&gt; Live Templates 设置护眼色Editor-&gt; Color Schemebackground 设置为 C7EDCC 插件Save Actions保存代码格式化 Alibaba Java Coding Guidelines代码规范检查 CamelCase单词格式切换，Switch easily between CamelCase, camelCase, snake_case and SNAKE_CASE. See Edit menu or use SHIFT + ALT + U. String Manipulation类似CamelCase]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>idea</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac 安装java9]]></title>
    <url>%2F2017%2F09%2Fmac%2Fmac-%E5%AE%89%E8%A3%85java9%2F</url>
    <content type="text"><![CDATA[官网下载jdk9官网地址 修改配置mac环境修改配置文件vim .bash_profile 12export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-9.jdk/Contents/Home/export PATH=$PATH:$JAVA_HOME/bin 使配置文件生效source .bash_profile]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins 入门使用]]></title>
    <url>%2F2017%2F09%2F%E5%B7%A5%E5%85%B7%2FJenkins-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[下载官网下载 jenkins.war或者 brew install jenkins 启动和停止启动12345678设置开机自启动：sudo launchctl load -w /Library/LaunchDaemons/org.jenkins-ci.plist取消开机自启动：sudo launchctl unload -w /Library/LaunchDaemons/org.jenkins-ci.plist手动启动：Java -jar jenkins.war后台启动(默认端口)：nohup java -jar jenkins.war &amp;后台启动(指定端口)：nohup java -jar jenkins.war -httpPort=88 &amp;后台启动(HTTPS)：nohup java -jar jenkins.war -httpsPort=88 &amp;sudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plist 停止1sudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plist 设置为中文 安装Locale Plugin， 重启生效。 配置【Manage Jenkins】&gt;【Configure System】&gt; 【Locale】 语言填zh_CN，勾选强制设置语言 运行远程脚本 安装Jenkins SSH plugin插件 在系统配置里配置Publish over SSH复制jenkins所在服务器密钥配置远程ssh server 增加构建步骤send files or ececute commands over SSH12345SSH Server Name：选个一个你在系统设置里配置的名字Transfer Set Source files：需要上传的文件（注意：相对于工作区的路径。看后面的配置可以填写多个，默认用,分隔）Remove prefix：移除目录（只能指定Transfer Set Source files中的目录，这里移除了target目录表示只将FinServer.war传到目标服务器，否则会在目标服务器创建target目录）Remote directory：远程目录（根据你的需求填写，这里没有填写默认会继承系统配置，即/mnt）Exec command：把你要执行的命令写在里面(这里的命令是在目标服务器上执行的) 只需要配置Exec command就可以这种远程执行脚本的方式，属于非交互式Shell，不会触发诸如~/.bash_profile之类文件的载入,需要 export设置环境变量或者source]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 备份mysqldump]]></title>
    <url>%2F2017%2F09%2FMySql%2Fmysql-%E5%A4%87%E4%BB%BDmysqldump%2F</url>
    <content type="text"><![CDATA[备份数据库的某表数据1mysqldump -u root -p database_name table_name table_name2 &gt; database_dump.txt 备份整个数据库的数据1mysqldump -u root -p database_name &gt; database_dump.txt 备份所有数据库1mysqldump -u root -p --all-databases &gt; database_dump.txt]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>备份数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 流程控制语句if/case]]></title>
    <url>%2F2017%2F09%2FMySql%2Fmysql-%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5if-case%2F</url>
    <content type="text"><![CDATA[if表达式 IF(expr1,expr2,expr3) 1select if(v=1,&apos;男&apos;,&apos;女&apos;) from t1 ; 如果条件判断多可以使用case when then。 case123456CASE &lt;单值表达式&gt; WHEN &lt;表达式值&gt; THEN &lt;SQL语句或者返回值&gt; WHEN &lt;表达式值&gt; THEN &lt;SQL语句或者返回值&gt; WHEN &lt;表达式值&gt; THEN &lt;SQL语句或者返回值&gt; ELSE &lt;SQL语句或者返回值&gt; END 简单Case函数写法12345select case v when 1 then &apos;男&apos; when 0 then &apos;女&apos; end from t1 ; Case搜索函数写法12345select case when v=1 then &apos;男&apos; when v=0 then &apos;女&apos; end from t1 ; 参考http://www.cnblogs.com/martinzhang/p/3220595.html]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oh-my-zsh使用]]></title>
    <url>%2F2017%2F09%2FLinux%2Foh-my-zsh%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[shell查看当前的shell cat /etc/shells 123456789# List of acceptable shells for chpass(1).# Ftpd will not allow users to connect who are not using# one of these shells./bin/bash/bin/csh/bin/ksh/bin/sh/bin/tcsh zsh 安装12CentOS 安装：sudo yum install -y zshmac 安装：brew install zsh zsh设置成系统默认shell，以代替bash chsh -s /bin/zsh oh-my-zshoh-my-zsh 是 zsh 的一个配置工具。安装 wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 安装插件 vim .zshrc 修改 plugins=(git) 为 plugins=(git autojump)使配置生效 source ~/.zshrc 修改主题.zshrc 中修改ZSH_THEME=’’ 打开sublime配置 alias st=’open -a “Sublime Text”‘]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>zsh</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PlainTasks使用-sublime待办插件]]></title>
    <url>%2F2017%2F09%2F%E5%B7%A5%E5%85%B7%2FPlainTasks%E4%BD%BF%E7%94%A8-sublime%E5%BE%85%E5%8A%9E%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[PlainTasksPlainTasks插件可以在我们的sublime编辑器里记录待办事，很方便，页面也很简单美观。 效果图 安装package control组件没有安装过插件的需要先安装package control组件才能安装插件Ctrl+ ` 调出console1import urllib.request,os; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), &apos;wb&apos;).write(urllib.request.urlopen( &apos;http://sublime.wbond.net/&apos; + pf.replace(&apos; &apos;,&apos;%20&apos;)).read()) 创建todo文件以下类型文件会被识别为todo文件 12345TODO*.todo*.todolist*.taskpaper*.tasks 常用操作 创建project：输入一行文字在后方加上英文冒号就可以被识别为project，project是可以被折叠的，比如在任何地方输入Projects: 创建task：⌘+enter或者⌘+i, ⌘+shift+enter自动加上创建时间 完成task：⌘+d，两次⌘+d取消 打标签：在行尾添加@ ，前边有空格 上下行互换位置：⌘+control+up/down 归档:归档文件所有完成的任务⌘+shift+A,已完成的任务移动至文档结尾; 分割线：— ✄ ——，输入–，按tab键 设置优先级：行尾加@critical、@high、@low、@today （严重、高、低、今天） 时间标记： 开始时间：输入s,两次tab键 @started(13-10-25 15:20) 开关：状态切换输入tg,两次tab键 @toggle(13-10-25 15:20) 创建：创建输入cr,两次tab键 @created(13-10-25 15:20) 预期：输入d,两次tab键 @due() @due(17.1.1 1:1) 指定时间 @due(+w) = @due( +7) 当前时间加1周 @due(1) 1下月的第一天 ，2下月第二天 @due(+1) = @due(+) 当前时间加1天 @due(+2:) = @due(+2.) 当前时间加2h @due(+.2) = @due(+0.2) 当前时间加2m @due(+2.2) 当前时间加2h2m @due(+2 2.2) 当前时间加2d2h2m]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>sublime</tag>
        <tag>todo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH 连接中断Write failed: Broken pipe]]></title>
    <url>%2F2017%2F09%2FLinux%2FSSH-%E8%BF%9E%E6%8E%A5%E4%B8%AD%E6%96%ADWrite-failed-Broken-pipe%2F</url>
    <content type="text"><![CDATA[ssh连接服务器后,一段时间不操作，再次操作时会出现Write failed: Broken pipe。解决方法：1、客户端设置：~/.ssh/ 文件夹中添加 config 文件，并添加下面的配置：ServerAliveInterval 602、在服务器的 /etc/ssh/sshd_config 中添加如下的配置：ClientAliveInterval 603、在登录命令添加参数：ssh -o ServerAliveInterval=60 user@sshserver 参考：http://blog.csdn.net/bbirdsky/article/details/21703555]]></content>
      <categories>
        <category>问题记录</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>问题记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim使用]]></title>
    <url>%2F2017%2F09%2Fvim%2Fvim%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[vim编辑粘贴代码格式化vim粘贴代码会有代码代码错乱的问题 在粘贴前先设置进入粘贴插入模式，即不会自动缩进和连续注释set paste然后再进入插入模式粘贴在粘贴插入模式下代码是不会自动按格式缩进的，需要使用nopaste设置回来set nopaste也可以在.vimrc中设置切换的快捷键，比如设置F9，则可以在.vimrc中加入：set pastetoggle=这样直接在插入模式按F9就会在“– 插入 –”模式和“– 插入（粘贴） –”模式中切换 移动1234^ 移到当前行的第一个非空字符$ 移到当前行的最后一个字符G 移到文件的最后一行gg 移到文件的第一行 文本操作1234567891011:r file 读入文件 file 内容，并插在当前行后:nr file 读入文件 file 内容，并插在第 n 行后:r !pwd 插入当前路径yy 复制一行，此命令前可跟数字，标识复制多行，如6yy，表示从当前行开始复制6行yw 复制一个字y$ 复制到行末]p 有缩进的粘贴，vim会自动调节代码的缩进格式化全文： gg=G 替换与操作123:g/text1/s/text2/text3 查找包含 text1 的行，用 text3 替换 text2:g/text/command 在所有包含 text 的行运行 command 所表示的命令:v/text/command 在所有不包含 text 的行运行 command 所表示的命令 保存文本和退出12345:w 保存文件但不退出 vi:w file 将修改保存在 file 中但不退出 vi:wq 或 ZZ 或 :x 保存文件并退出 vi:q! 不保存文件，退出 vi:e! 放弃所有修改，从上次保存文件开始再编辑 vi 中的选项12:set number 显示行数:set nonumber 取消显示行数 vi 中的 shell 转义命令1234567:!command 执行 shell 的 command 命令，如 :!ls:!! 执行前一个 shell 命令:r!command 读取 command 命令的输入并插入，如 :r!ls 会先执行 ls，然后读入内容:w!command 将当前已编辑文件作为 command 命令的标准输入并执行 command 命令，如 :w!grep all:cd directory 将当前工作目录更改为 directory 所表示的目录:sh 将启动一个子 shell，使用 ^d(ctrl+d) 返回 vi:so file 在 shell 程序 file 中读入和执行命令 vim 分屏123456789101112131415161718192021222324252627282930313233343536分屏启动使用大写的O参数来垂直分屏。vim -On file1 file2 ...使用小写的o参数来水平分屏。vim -on file1 file2 ...n是数字，表示分成几个屏关闭分屏关闭当前窗口。Ctrl+W c关闭当前窗口，如果只剩最后一个了，则退出Vim。Ctrl+W q分屏上下分割当前打开的文件。Ctrl+W s上下分割，并打开一个新的文件。:sp filename左右分割当前打开的文件。Ctrl+W v左右分割，并打开一个新的文件。:vsp filename屏幕尺寸让所有的屏都有一样的高度。Ctrl+W =增加高度。Ctrl+W +减少高度。Ctrl+W -:res(ize) num 例如：:res 5，显示行数调整为5行:res(ize)+num 把当前窗口高度增加num行:res(ize)-num 把当前窗口高度减少num行给窗口重命名:f file]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmux使用]]></title>
    <url>%2F2017%2F09%2F%E5%B7%A5%E5%85%B7%2Ftmux%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[tmuxtmux是linux中一种管理窗口的程序。tmux提供了一个窗体组随时存储和恢复的功能。 tmux的基本概念tmux是一个终端复用器(terminal multiplexer).tmux有三个概念：会话(Session)，窗口(Window)，面板(Pane)。当你输入tmux后, tmux实际做的事是首先创建一个会话(Session), 然后在这个会话中创建一个窗口, 你可以继续创建多个窗口(Window), 每个窗口初始只包含一个面板, 继续分屏后, 会出现多个面板(Pane) 你在其中看到的终端实际上都属于tmux的某个面板。 tmux安装1[root@VM_1_49_centos ~]# yum install tmux 命令行 tmux new[-session] -s name -d 新建会话(-d 是否在后台) tmux new -s name -n windowname 新建会话及窗口 tmux at[tach] -t session 重新连接(-t 后接会话名称) tmux ls 显示保存的会话 tmux kill-session -t session 删除会话 常用操作所有快捷键执行方式：1control+b 告诉Tmux我要用Tmux的快捷键。 C-b ? 列出所有快捷键, 按q或Esc返回 C-b d detach当前会话,可暂时返回Shell界面，输入tmux attach能够重新进入之前会话 C-b s 选择并切换会话；在同时开启了多个会话时使用 快捷键sesson tmux new -s session_name creates a new tmux session named session_name tmux attach -t session_name attaches to an existing tmux session named session_name tmux switch -t session_name switches to an existing session named session_name tmux list-sessions lists existing tmux sessions tmux detach (prefix + d) detach the currently attached session C-b $ 改变会话的名字 1234567# 创建一个新的session$ tmux new -s &lt;name-of-my-session&gt;# 在当前session中创建一个新的Session, 并保证之前session依然存在# C-b : 然后输入下面命令new -s &lt;name-of-my-new-session&gt;# 进入名为test的session$ tmux attach -t test window C-b c 创建一个新窗口 C-b &amp; 关闭当前窗口 C-b w 列出所有的窗口选择 C-b p 切换到上一个窗口 C-b n 切换到下一个窗口 C-b 窗口号 使用窗口号切换窗口(例如窗口号为1的, 则C-b 1) C-b , 重命名当前窗口，便于识别各个窗口 C-b . 修改当前编号 pane C-b % 横向分Terminal C-b “ 纵向分Terminal C-b 方向键 则会在自由选择各面板 C-b x 关闭当前pane C-b q 显示面板编号 C-b o 选择当前窗口中下一个面板 C-b 数字 选择指定窗口 C-b z 暂时把一个窗体放到最大 开启批量执行（同步输入）C-b后输入:set synchronize-panes ，输入:set sync [TAB]键可自动补齐 设置鼠标C-b : 进入命令行 123setw mode-mouse on #单个窗口启用鼠标滚轮来卷动窗口内容setw -g mode-mouse on #所有窗口启用鼠标滚轮来卷动窗口内容 或者在配置文件里设置~/.tmux.conf：1234setw -g mouse-resize-pane on #开启用鼠标拖动调节pane的大小setw -g mouse-select-pane on #开启用鼠标点击pane来激活该panesetw -g mouse-select-window on #开启用鼠标点击来切换活动window 状态栏的窗口名称setw -g mode-mouse on #开启所有窗口启用鼠标滚轮来卷动窗口内容 新版本设置12345set-option -g mouse on# 将window的起始设置为1 set -g base-index 1# 将pane的起始下标设为1 set -g pane-base-index 1 配置之后进入命令行，输入 tmux source ~/.tmux.conf，使配置生效。 进入vi copy模式1234#visetw -g mode-keys vibind -t vi-copy v begin-selectionbind -t vi-copy y copy-selection 或者使用鼠标选中，按y复制 复制到系统剪贴板中Mac 下如果用 iterm2 可以在 preference 下选择 Applications in terminal may access clipboard。 参考http://cenalulu.github.io/linux/tmux/http://guoqiao.me/post/2016/tmux]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tmux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次npm i 运行错误]]></title>
    <url>%2F2017%2F09%2F%E5%89%8D%E7%AB%AF%2F%E8%AE%B0%E4%B8%80%E6%AC%A1npm-i-%E8%BF%90%E8%A1%8C%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[执行npm i出错: 1234npm ERR! code EINTEGRITYnpm ERR! sha1-eCA6TRwyiuHYbcpkYONptX9AVa4= integrity checksum failed when using sha1: wanted sha1-eCA6TRwyiuHYbcpkYONptX9AVa4= but got sha1-tURkGu3SzDOsTOBkGT5fXZCH7as=. (26893 bytes)npm ERR! A complete log of this run can be found in: 解决方法：npm cache clean –force 强制清除npm 的 cache或者重新执行 npm i]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 安装node&npm]]></title>
    <url>%2F2017%2F09%2FLinux%2FLinux-%E5%AE%89%E8%A3%85node-npm%2F</url>
    <content type="text"><![CDATA[官网地址node官网 安装步骤12345sudo yum install gcc-c++ makecurl --silent --location https://rpm.nodesource.com/setup_8.x | sudo bash -sudo yum -y install nodejs 说明：sudo bash 作为超级用户运行”bash” 查看版本123node -vnpm -v]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F09%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开始自己的个人博客]]></title>
    <url>%2F2016%2F12%2F%E5%BC%80%E5%A7%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[使用hexo开始自己的博客。开篇先记录下hexo的使用。 安装安装特别简单，安装官网的步骤来很快搞定。12345npm install hexo-cli -ghexo init blogcd blognpm installhexo server 常用命令init$ hexo init [folder]新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new$ hexo new [layout] &lt;title&gt;新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 generate$ hexo generate生成静态文件。 选项 描述-d, –deploy 文件生成后立即部署网站-w, –watch 监视文件变动 publish$ hexo publish [layout] &lt;filename&gt;发表草稿。 server$ hexo server启动服务器。默认情况下，访问网址为： http://localhost:4000/。 选项 描述-p, –port 重设端口-s, –static 只使用静态文件-l, –log 启动日记记录，使用覆盖记录格式 deploy$ hexo deploy部署网站。 参数 描述-g, –generate 部署之前预先生成静态文件 render$ hexo render &lt;file1&gt; [file2] ...渲染文件。 参数 描述-o, –output 设置输出路径 migrate$ hexo migrate &lt;type&gt;从其他博客系统 迁移内容。 clean$ hexo clean清除缓存文件 (db.json) 和已生成的静态文件 (public)。 list$ hexo list &lt;type&gt;列出网站资料。 version$ hexo version显示 Hexo 版本。 选项安全模式$ hexo --safe在安全模式下，不会载入插件和脚本。当您在安装新插件遭遇问题时，可以尝试以安全模式重新执行。 调试模式$ hexo --debug在终端中显示调试信息并记录到 debug.log。当您碰到问题时，可以尝试用调试模式重新执行一次，并 提交调试信息到 GitHub。 简洁模式$ hexo --silent隐藏终端信息。 自定义配置文件的路径$ hexo --config custom.yml自定义配置文件的路径，执行后将不再使用 _config.yml。 显示草稿$ hexo --draft显示 source/_drafts 文件夹中的草稿文章。 自定义 CWD$ hexo --cwd /path/to/cwd自定义当前工作目录（Current working directory）的路径。 添加文章评论disq注册账号 https://disqus.com/，在theme的_config.yml中设置12345# Disqusdisqus: enable: true shortname: http-codr-top count: true 添加头像在theme的_config.yml中设置1avatar: /images/avatar.jpg 添加logoFavicon在线制作工具 http://tool.lu/favicon/，在theme的_config.yml中设置 1favicon: images/favicon.ico 炫酷动态背景12# Canvas-nestcanvas_nest: true 实现统计功能安装wordcount插件1sudo npm install hexo-wordcount --save 在theme的_config.yml中设置12345post_wordcount: item_text: true wordcount: true min2read: true separated_meta: true 阅读次数统计next集成了leancloud https://leancloud.cn/，在leancloud官网注册，设置leancloud_visitors12leancloud_visitors: enable: true 文章资源文件夹12_config.ymlpost_asset_folder: true 编写和发布草稿创建文章时：hexo new draft Test查看草稿的效果：hexo s –draft，或者在 _config.yml文件中进行配置render_drafts: true将草稿发布到_posts目录中：12hexo publish [layout] &lt;title&gt;比如：hexo publish post Test 提交源码到github上12345$ git init$ git remote add origin git@github.com:username/username.github.io.git$ git add .$ git commit -m &quot;blog&quot;$ git push origin master:blog 参考http://cherryblog.site/hexo-3.html]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
